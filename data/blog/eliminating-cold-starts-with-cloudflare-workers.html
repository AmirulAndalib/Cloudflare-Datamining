<div class="mb2 gray5">4 min read</div>
<div class="post-content lh-copy gray1">
	<figure class="kg-card kg-image-card ">

		<img src="https://cf-assets.www.cloudflare.com/slt3lc6tev37/1oYOYNxDVXur9l8h5l6ZHe/618d7c5574d708867e56079a02cda735/Serverless-Week-Cold-Starts_2x-3.png" alt="" class="kg-image" width="2000" height="1015" loading="lazy">

	</figure>
	<p>A “cold start” is the time it takes to load and execute a new copy of a serverless function for the first time. It’s a problem that’s both complicated to solve and costly to fix. Other serverless platforms make you choose between suffering from random increases in execution time, or paying your way out with synthetic requests to keep your function warm. Cold starts are a horrible experience, especially when serverless containers can take full <i>seconds</i> to warm up.</p>
	<figure class="kg-card kg-image-card ">

		<img src="https://cf-assets.www.cloudflare.com/slt3lc6tev37/7I5ZmdHAJG6sALtXOcCJvD/0ba71ee0ddff8e45df7ce9a0e8594288/cold-start-clock_2x.png" alt="" class="kg-image" width="973" height="823" loading="lazy">

	</figure>
	<p>Unlike containers, Cloudflare Workers utilize isolate technology, which measure cold starts in single-digit milliseconds. Well, at least they <i>did</i>. Today, we’re removing the need to worry about cold starts entirely, by introducing support for Workers that have no cold starts at all – that’s right, zero. Forget about cold starts, warm starts, or... any starts, with Cloudflare Workers you get always-hot, raw performance in more than 200 cities worldwide.</p>
	<h3>Why is there a cold start problem?</h3>
	<p>It’s impractical to keep everyone’s functions warm in memory <i>all</i> the time. Instead, serverless providers only warm up a function after the first request is received. Then, after a period of inactivity, the function becomes cold again and the cycle continues.</p>
	<p>For Workers, this has never been much of a problem. In contrast to containers that can spend full seconds spinning up a new containerized process for each function, the isolate technology behind Workers allows it to warm up a function in under 5 milliseconds.</p>
	<figure class="kg-card kg-image-card ">

		<img src="https://cf-assets.www.cloudflare.com/slt3lc6tev37/CyIMgGPifYO2zfgd8Y2XV/f92b7763c8abbfeeaae13aca3a8c8122/isolates-model_2x-1.png" alt="" class="kg-image" width="1600" height="800" loading="lazy">

	</figure>
	<p><i>Learn more about how isolates enable Cloudflare Workers to be performant and secure</i> <a href="https://blog.cloudflare.com/cloud-computing-without-containers"><i>here.</i></a></p>
	<p>Cold starts are ugly. They’re unexpected, unavoidable, and cause unpredictable code execution times. You shouldn’t have to compromise your customers’ experience to enjoy <a href="https://www.cloudflare.com/learning/serverless/what-is-serverless">the benefits of serverless</a>. In a collaborative effort between our Workers and Protocols teams, we set out to create a solution where you never have to worry about cold starts, warm starts, or pre-warming ever again.</p>
	<h3>How is a zero cold start even possible?</h3>
	<p>Like many features at Cloudflare, security and encryption make our network more intelligent. Since 95% of Worker requests are securely handled over HTTPS, we engineered a solution that uses the Internet’s encryption protocols to our advantage.</p>
	<p>Before a client can send an HTTPS request, it needs to establish a secure channel with the server. This process is known as “handshaking” in the <a href="https://www.cloudflare.com/learning/ssl/what-happens-in-a-tls-handshake">TLS</a>, or Transport Layer Security, protocol. Most clients also send a hostname (e.g. cloudflare.com) in that handshake, which is referred to as the <a href="https://www.cloudflare.com/learning/ssl/what-is-sni">SNI</a>, or Server Name Indication. The server receives the handshake, sends back a certificate, and now the client is allowed to send its original request, encrypted.</p>
	<p>Previously, Workers would only load and compile after the <i>entire</i> handshake process was complete, which involves two round-trips between the client and server. But wait, we thought, if the hostname is present in the handshake, why wait until the entire process is done to preload the Worker? Since the handshake takes some time, there is an opportunity to warm up resources during the waiting time before the request arrives.</p>
	<figure class="kg-card kg-image-card ">

		<img src="https://cf-assets.www.cloudflare.com/slt3lc6tev37/20vUSqi8x0NQ2FPLeQ807y/dfd5a0f7a396b9f45af4f4ac5003309b/Workers-handshake-after_2x.png" alt="" class="kg-image" width="1509" height="1004" loading="lazy">

	</figure>
	<p>With our newest optimization, when Cloudflare receives the first packet during TLS negotiation, the “ClientHello,” we hint the Workers runtime to eagerly load that hostname’s Worker. After the handshake is done, the Worker is warm and ready to receive requests. Since it only takes 5 milliseconds to load a Worker, and the average latency between a client and Cloudflare is more than that, the cold start is zero. The Worker starts executing code the moment the request is received from the client.</p>
	<figure class="kg-card kg-image-card ">

		<img src="https://cf-assets.www.cloudflare.com/slt3lc6tev37/7G67cFXFAeoyLca4YxgeqC/ec36e20d6cf7d639581b54998d85237b/Workers-handshake-before-_2x.png" alt="" class="kg-image" width="1509" height="1004" loading="lazy">

	</figure>
	<h3>When are zero cold starts available?</h3>
	<p>Now, and for everyone! We’ve rolled out this optimization to all Workers customers and it is in production today. There’s no extra fee and no configuration change required. When you build on Cloudflare Workers, you build on an intelligent, distributed network that is constantly pushing the bounds of what's possible in terms of performance.</p>
	<p>For now, this is only available for Workers that are deployed to a “root” hostname like “example.com” and not specific paths like “example.com/path/to/something.” We plan to introduce more optimizations in the future that can preload specific paths.</p>
	<h3>What about performance beyond cold starts?</h3>
	<p>We also recognize that performance is more than just zero cold starts. That’s why we announced the beta of <a href="https://www.cloudflare.com/workers-unbound-beta">Workers Unbound</a> earlier this week. Workers Unbound has the simplicity and performance of Workers with no limits, just raw performance.</p>
	<p>Workers, equipped with zero cold starts, no CPU limits, and a network that spans over 200 cities is prime and ready to take on any serious workload. Now that’s performance.</p>
	<h3>Interested in deploying with Workers?</h3>
	<ul>
		<li>
			<p>Learn more about <a href="https://workers.dev">Cloudflare Workers</a></p>
		</li>
		<li>
			<p>Join the Workers Unbound <a href="https://www.cloudflare.com/workers-unbound-beta">Beta</a></p>
		</li>
		<li>
			<p>Try our new language support for <a href="https://github.com/cloudflare/python-worker-hello-world">Python</a> and <a href="https://github.com/cloudflare/kotlin-worker-hello-world">Kotlin</a></p>
		</li>
	</ul>
</div>