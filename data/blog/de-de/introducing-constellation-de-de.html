<div class="mb2 gray5">7 min read</div>
<div class="post-content lh-copy gray1">
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2023/05/image4-7-4.png" class="kg-image" alt="" loading="lazy" width="1200" height="675"></figure>
	<p>Die Produkte und Funktionen im Ökosystem von Cloudflare Workers decken Rechenleistung, Hosting, Speicherplatz, Datenbanken, Streaming, Netzwerkdienste, Sicherheit und <a href="https://developers.cloudflare.com" target="_blank">vieles mehr</a> ab. Wir haben <a href="https://blog.cloudflare.com/welcome-to-wildebeest-the-fediverse-on-cloudflare">nachgewiesen</a>, dass sich komplexe und weltweit skalierbare Anwendungen auf unserem Lösungsstapel entwickeln lassen, und dies auch <a href="https://blog.cloudflare.com/de-de/technology-behind-radar2-de-de">dokumentiert</a>, um zur Abkehr von traditionellen Software-Architekturen zu inspirieren.</p>
	<p>Heute freuen wir uns, Constellation in den Lösungsstapel von Cloudflare aufnehmen zu können. Damit haben Entwickler die Möglichkeit, vortrainierte Modelle maschinellen Lernens und Inferenzaufgaben auf dem Cloudflare-Netzwerk auszuführen.</p>
	<h2 id="ein-weiterer-baustein-unserer-supercloud">Ein weiterer Baustein unserer Supercloud</h2>
	<p><a href="https://en.wikipedia.org/wiki/Machine_learning" target="_blank">Maschinelles Lernen</a> und künstliche Intelligenz (KI) sind in letzter Zeit in aller Munde. Tatsächlich nutzen wir diese Technologien aber schon seit Jahren im Alltag, selbst wenn uns das manchmal gar nicht bewusst ist. Unsere Handys, Computer, Autos und Helfer für das Smart Home sind nur einige Beispiele dafür. Diese Technologien sind allgegenwärtig.</p>
	<p>Doch in den Entwickleralltag sind sie bislang noch nicht eingekehrt. Entwickler müssen häufig die Mathematik verstehen, auf der sie aufbauen. Hinzu kommt, dass Software und Tools in der Regel komplex und nicht unbedingt alle an einem Ort gebündelt sind. Außerdem sind die Hardware und Cloud-Dienste, die zum Betrieb der Frameworks und zur Verarbeitung der Daten benötigt werden, kostspielig.</p>
	<p><strong>Deshalb erweitern wir heute unseren Lösungsstapel um eine weitere Funktion, die es allgemein ermöglicht, Machine Learning-Modelle einzusetzen und Inferenzaufgaben auf Cloudflare Workers auszuführen.</strong></p>
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2023/05/image2-8.png" class="kg-image" alt="" loading="lazy" width="1784" height="510"></figure>
	<h2 id="einf%C3%BChrung-von-constellation">Einführung von Constellation</h2>
	<p>Dank Constellation können Sie Inferenzaufgaben schnell und mit geringer Latenz mithilfe vortrainierter Machine Learning-Modell nativ auf Cloudflare Workers ausführen.</p>
	<p>Hier sind ein paar Beispiele für Anwendungen, die mithilfe von Constellation ausgeführt werden können:</p>
	<p>● Bild- oder Audioklassifizierung oder Objekterkennung</p>
	<p>● Erkennung von Anomalien in Daten</p>
	<p>● Übersetzung, Zusammenfassung oder Sentimentanalyse von Texten</p>
	<p>● Verarbeitung natürlicher Sprache</p>
	<p>● Sentimentanalyse</p>
	<p>● Spracherkennung oder Text-zu-Sprache-Umwandlung</p>
	<p>● Beantwortung von Fragen</p>
	<p>Entwickler können alle unterstützten Modelle bei Constellation hochladen. Sie können sie unabhängig trainieren oder vortrainierte Modelle von Machine Learning-Plattformen wie <a href="https://huggingface.co/models?library=onnx&amp;sort=downloads" target="_blank">HuggingFace</a> oder <a href="https://github.com/onnx/models" target="_blank">ONNX Zoo</a>herunterladen.</p>
	<p>Allerdings möchte nicht jeder Modelle trainieren oder das Internet nach noch nicht getesteten Modellen durchforsten. Aus diesem Grund wird Cloudflare auch eine Liste überprüfter und direkt einsatzbereiter Modelle bereitstellen.</p>
	<p>Wir haben Constellation mit Blick auf benutzerfreundliche APIs so konzipiert, dass die Lösung Entwicklern ein großartiges Anwendererlebnis bietet. Hier ist ein Beispiel für den Einstieg.</p>
	<h2 id="anwendung-zur-bildklassifizierung">Anwendung zur Bildklassifizierung</h2>
	<p>In diesem Beispiel werden wir eine Anwendung zur Bildklassifizierung entwickeln, die die Inferenz-API von Constellation und das Convolutional Neural Network (CNN) von <a href="https://github.com/onnx/models/blob/main/vision/classification/squeezenet/README.md" target="_blank">SqueezeNet</a> einsetzt, das mit mehr als einer Million Bildern aus der quelloffenen Datenbank <a href="https://www.image-net.org" target="_blank">ImageNet</a>vortrainiert wurde und in der Lage ist, Bilder höchstens 1.000 Kategorien zuzuordnen.</p>
	<p>SquezeNet nimmt einen Abgleich mit <a href="https://en.wikipedia.org/wiki/AlexNet" target="_blank">AlexNet</a>vor, einem der ursprünglichen CNNs und Benchmarks für die Bildklassifizierung, ist dabei viel (ungefähr dreimal) schneller, erheblich (etwa 500-mal) kleiner und erreicht trotzdem eine vergleichbare Genauigkeit. Aufgrund ihrer geringen Größe ist die Lösung perfekt für den Einsatz auf tragbaren Geräten mit begrenzten Ressourcen und maßgeschneiderter Hardware geeignet.</p>
	<p>Zunächst erstellen wir mit der ONNX-Laufzeitumgebung ein neues Constellation-Projekt. Wrangler verfügt nun über eine Constellation-Integration mit dem Schlagwort „constellation“.</p><!--kg-card-begin: markdown-->
	<pre><code>$ npx wrangler constellation project create "image-classifier" ONNX
</code></pre>
	<!--kg-card-end: markdown-->
	<p>Jetzt erstellen wir die wrangler.toml-Konfigurationsdatei mit dieser Projektbindung:</p><!--kg-card-begin: markdown-->
	<pre><code class="language-yaml"># Top-level configuration
name = "image-classifier-worker"
main = "src/index.ts"
compatibility_date = "2022-07-12"

constellation = [
    {
      binding = 'CLASSIFIER',
      project_id = '2193053a-af0a-40a6-b757-00fa73908ef6'
    },
]
</code></pre>
	<!--kg-card-end: markdown-->
	<p>Installieren Sie die Client-API-Bibliotehk von Constellation:</p><!--kg-card-begin: markdown-->
	<pre><code>$ npm install @cloudflare/constellation --save-dev
</code></pre>
	<!--kg-card-end: markdown-->
	<p>Laden Sie das vortrainierte SqueezeNet 1.1 ONNX-Modells in das Projekt hoch.</p><!--kg-card-begin: markdown-->
	<pre><code>$ wget https://github.com/microsoft/onnxjs-demo/raw/master/docs/squeezenet1_1.onnx
$ npx wrangler constellation model upload "image-classifier" "squeezenet11" squeezenet1_1.onnx
</code></pre>
	<!--kg-card-end: markdown-->
	<p>Wie oben bereits erwähnt ordnet SqueezeNet Bilder nicht mehr als 1.000 Objektklassen zu. Diese Klassen nehmen die Gestalt einer Liste aus Synonymringen bzw. Synsets an. Ein <a href="http://wordnet-rdf.princeton.edu/pwn30/01440764-n" target="_blank">Synset</a> verfügt über eine Kennnummer (ID) und eine Beschriftung. Es leitet sich aus der <a href="https://wordnet.princeton.edu" target="_blank">WordNet</a>-<a href="https://wordnet.princeton.edu/documentation" target="_blank">Datenbankterminologie</a>von Princeton ab, die auch für die Beschriftungen der Bilddatenbank <a href="https://www.image-net.org/about.php" target="_blank">ImageNet</a>verwendet wird.</p>
	<p>Um die Ergebnisse von SqueezeNet in von Menschen lesbare Bildklassen zu übersetzen, wird eine Datei benötigt, die die Synset-IDs (die von dem Modell ausgegeben werden) den zugehörigen Beschriftungen zuordnet.</p><!--kg-card-begin: markdown-->
	<pre><code>$ mkdir src; cd src
$ wget https://raw.githubusercontent.com/microsoft/onnxjs-demo/master/src/data/imagenet.ts
</code></pre>
	<!--kg-card-end: markdown-->
	<p>Zu guter Letzt müssen wir unser Bildklassifizierungsskript schreiben und implementieren:</p><!--kg-card-begin: markdown-->
	<pre><code class="language-javascript">import { imagenetClasses } from './imagenet';
import { Tensor, run } from '@cloudflare/constellation';

export interface Env {
    CLASSIFIER: any,
}

export default {
    async fetch(request: Request, env: Env, ctx: ExecutionContext) {
        const formData = await request.formData();
        const file = formData.get("file");
        const data = await file.arrayBuffer();
        const result = await processImage(env, data);
        return new Response(JSON.stringify(result));
    },
};

async function processImage(env: Env, data: ArrayBuffer) {
    const input = await decodeImage(data)

    const tensorInput = new Tensor("float32", [1, 3, 224, 224], input)

    const output = await run(env.CLASSIFIER, "MODEL-UUID", tensorInput);

    const probs = output.squeezenet0_flatten0_reshape0.value
    const softmaxResult = softmax(probs)
    const results = imagenetClasses(softmaxResult, 5);
    const topResult = results[0];
    return topResult
}
</code></pre>
	<!--kg-card-end: markdown-->
	<p>Dieses Skript liest ein Bild aus der Anfrage aus, entschlüsselt es in einen multidimensionalen float32-Tensor (zurzeit entschlüsseln wir nur PNGs, es können aber weitere Formate hinzugefügt werden), speist es in das in Constellation betriebene SqueezeNet-Modell ein, empfängt die Ergebnisse, ordnet sie anhand der ImageNet-Klassenliste zu und gibt für das Bild vom Menschen lesbare Beschriftungen aus.</p>
	<p>Eigentlich ziemlich einfach, oder? Wir testen das jetzt einmal:</p><!--kg-card-begin: markdown-->
	<pre><code>$ curl https://ai.cloudflare.com/demos/image-classifier -F file=@images/mountain.png | jq .name

alp

$ curl https://ai.cloudflare.com/demos/image-classifier -F file=@images/car.png | jq .name

convertible

$ curl https://ai.cloudflare.com/demos/image-classifier -F file=@images/dog.png | jq .name

Ibizan hound
</code></pre>
	<!--kg-card-end: markdown-->
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2023/05/Screenshot-2023-05-15-at-12.55.21.png" class="kg-image" alt="" loading="lazy" width="1888" height="682"></figure>
	<p>Sie sehen hier die Wahrscheinlichkeiten in Aktion. Bei der Alm und dem Cabrio ist sich das Modell ziemlich sicher, bei dem Podenco Ibicenco ist die Wahrscheinlichkeit dagegen niedriger. Tatsächlich gehört der Hund auf dem Bild einer anderen Rasse an.</p>
	<p>Diese kleine Applikation zeigt, wie leicht und schnell mit der Verwendung von Machine Learning-Modellen und Constellation begonnen werden kann, wenn Anwendungen auf Workers entwickelt werden. Sie können sich den vollständigen Quellcode <a href="https://developers.cloudflare.com/constellation/get-started/first-constellation-worker" target="_blank">hier</a> ansehen und ihn selbst implementieren.</p>
	<p><a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)" target="_blank">Transformer</a>s wurden von Google eingeführt. Es handelt sich um Deep Learning-Modelle, die entwickelt wurden, um sequenzielle Eingabedaten zu verarbeiten. Sie werden in der Regel zur Verarbeitung natürlicher Sprachen (Natural Language Processing – NLP) verwendet, etwa für Übersetzungen, Zusammenfassungen oder Sentimentanalysen, sowie für Aufgaben des computerbasierten Sehens (Computer Vision –CV) wie Bildklassifizierung.</p>
	<p><a href="https://github.com/xenova/transformers.js" target="_blank">Transformers.js</a>ist eine beliebte Demo, die Transformer-Modelle aus HuggingFace lädt und sie in Ihrem Browser mit der zu <a href="https://developers.cloudflare.com/workers/platform/web-assembly" target="_blank">WebAsssembly</a> kompilierten Laufzeitumgebung ONNX betreibt. Wir haben eine Portierung für diese Demo vorgenommen, sodass sie stattdessen Constellation-APIs nutzt.</p>
	<p>Hier ist der Link zu unserer Version: <a href="https://transformers-js.pages.dev" target="_blank">https://transformers-js.pages.dev/</a></p>
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2023/05/image3-5.png" class="kg-image" alt="" loading="lazy" width="1999" height="1195"></figure>
	<h2 id="interoperabilit%C3%A4t-mit-workers">Interoperabilität mit Workers</h2>
	<p>Interessant an Constellation ist auch, dass die Lösung nativ in Workers betrieben wird und daher mit anderen Produkten und APIs in unserem Lösungsstapel orchestriert werden kann. Sie können beispielsweise KV, R2, D1, Queues oder sogar E-Mails verwenden.</p>
	<p>Hier ist ein Beispiel für einen Worker, der E-Mails von Ihrer Domain bei Cloudflare <a href="https://developers.cloudflare.com/email-routing/email-workers" target="_blank">erhält</a>, und zwar mittels <a href="https://developers.cloudflare.com/email-routing" target="_blank">E-Mail-Routing</a>, Constellation mit dem <a href="https://huggingface.co/Xenova/t5-small/tree/main/onnx" target="_blank">t5-small</a>-Sentimentanalysemodell betreibt, eine Kopfzeile mit dem sich daraus ergebenden Score hinzufügt und sie an die Bestimmungsadresse weiterleitet.</p><!--kg-card-begin: markdown-->
	<pre><code class="language-javascript">import { Tensor, run } from '@cloudflare/constellation';
import * as PostalMime from 'postal-mime';

export interface Env {
    SENTIMENT: any,
}

export default {
  async email(message, env, ctx) {
    const rawEmail = await streamToArrayBuffer(event.raw, event.rawSize);
    const parser = new PostalMime.default();
    const parsedEmail = await parser.parse(rawEmail);

    const input = tokenize(parsedEmail.text)
    const output = await run( env.SENTIMENT, "MODEL-UUID", input);


    var headers = new Headers();
    headers.set("X-Sentiment", idToLabel[output.label]);
    await message.forward("gooddestination@example.com", headers);
  }
}
</code></pre>
	<!--kg-card-end: markdown-->
	<p>Jetzt können Sie Gmail oder jeden beliebigen E-Mail-Client nutzen, um auf ihre Nachrichten eine Regel auf Grundlage der „X-Sentiment“-Kopfzeile anzuwenden. So können Sie beispielsweise E-Mails, die Beschimpfungen oder aggressive Ausdrücke enthalten, von Ihrem Posteingang fernhalten und diese stattdessen direkt in einen separaten Ordner abgelegen lassen.</p>
	<h2 id="erste-schritte-mit-constellation">Erste Schritte mit Constellation</h2>
	<p>Constellation ist ab heute als Private Beta verfügbar. Um sich auf die Warteliste setzen zu lassen, klicken Sie im Dashboard in der Registerkarte „Workers“ unter Ihrem Account auf die Schaltfläche „<a href="https://dash.cloudflare.com/login" target="_blank">Zugang anfordern</a>“ (Request access). Das Onboarding der Konten wird in mehreren Schüben erfolgen. Sobald Ihr Konto dafür aktiviert wurde, erhalten Sie eine E-Mail.</p>
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2023/05/image1-25.png" class="kg-image" alt="" loading="lazy" width="1999" height="1426"></figure>
	<p>In der Zwischenzeit können Sie sich mithilfe der <a href="https://developers.cloudflare.com/constellation" target="_blank">Entwicklerdokumentation für Constellation</a>näher mit dem Produkt, seiner Funktionsweise und den zugehörigen APIs vertraut machen. Constellation kann über Wrangler, unser Kommandozeilen-Tool zur Konfiguration, Entwicklung und Implementierung von Anwendungen mit Cloudflare-Entwicklerprodukten, verwendet oder direkt im Dashboard-Interface verwaltet werden.</p>
	<p>Uns interessiert sehr, wie Sie Machine Learning/KI mit Ihren Anwendungen einsetzen möchten. Constellation wird sich mit höheren Obergrenzen, eine größerer Zahl unterstützter Umgebungen und größeren Modellen weiter verbessern, aber wir würden gern Ihre Meinung hören. Ihr Feedback wird auf jeden Fall in unsere Entscheidungen hinsichtlich unseres künftigen Angebots einfließen.</p>
	<p>Es wäre noch eine letzte Sache anzumerken: In diesem Beitrag ging es darum, wie Sie Workers erstellen können, die Constellation nutzen. Constellation selbst wurde aber ebenfalls mithilfe von WebAssembly, Workers, R2 und unseren APIs entwickelt. In Kürze werden wir in einem weiteren Blogbeitrag näher auf die Entwicklung eingehen.</p>
	<p>Sie können wie gewohnt über unseren <a href="https://discord.cloudflare.com" target="_blank">Discord-Kanal für Entwickler</a> (indem Sie dem #constellation-Kanal beitreten) oder über das <a href="https://community.cloudflare.com/c/developers/constellation/97" target="_blank">Community-Forum</a> mit uns in Kontakt treten. Unser Team ist für Sie da.</p>
</div>