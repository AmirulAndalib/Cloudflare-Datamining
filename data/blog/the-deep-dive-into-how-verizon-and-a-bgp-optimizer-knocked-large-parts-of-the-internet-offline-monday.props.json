{
	"locale": "en-us",
	"post": {
		"access": true,
		"authors": [
			{
				"id": "5d1644b141acde0011a94f36",
				"name": "Martin J Levy",
				"slug": "martin-levy",
				"profile_image": "https://blog-cloudflare-com-assets.storage.googleapis.com/2019/07/A03361C5-7DAD-4D01-8A98-A1400DF38E31.jpeg",
				"cover_image": "http://blog.cloudflare.com/content/images/2018/08/general@2x-102.png",
				"bio": null,
				"website": null,
				"location": null,
				"facebook": null,
				"twitter": "@mahtin",
				"meta_title": null,
				"meta_description": null,
				"url": "http://blog.cloudflare.com/author/martin-levy/"
			}
		],
		"canonical_url": null,
		"codeinjection_foot": null,
		"codeinjection_head": null,
		"comment_id": "5d13d0e644e1b900384a1f99",
		"comments": false,
		"created_at": "2019-06-26T21:09:10.000+01:00",
		"custom_excerpt": "On Monday we wrote about a painful Internet wide route leak. We wrote that this should never have happened because Verizon should never have forwarded those routes to the rest of the Internet. Today we will dive into the archived routing data and analyze it.",
		"custom_template": null,
		"email_subject": null,
		"excerpt": "On Monday we wrote about a painful Internet wide route leak. We wrote that this should never have happened because Verizon should never have forwarded those routes to the rest of the Internet. Today we will dive into the archived routing data and analyze it.",
		"feature_image": "http://blog.cloudflare.com/content/images/2019/06/396531-bgplay-3-1.png",
		"feature_image_alt": null,
		"feature_image_caption": null,
		"featured": false,
		"frontmatter": null,
		"html": "<h3 id=\"a-recap-on-what-happened-monday\">A recap on what happened Monday</h3><p>On Monday we <a href=\"http://blog.cloudflare.com/how-verizon-and-a-bgp-optimizer-knocked-large-parts-of-the-internet-offline-today/\">wrote</a> about a painful Internet wide route leak. We wrote that this should never have happened because Verizon should never have forwarded those routes to the rest of the Internet. That blog entry came out around 19:58 UTC, just over seven hours after the route leak finished (which will we see below was around 12:39 UTC). Today we will dive into the archived routing data and analyze it. The format of the code below is meant to use simple shell commands so that any reader can follow along and, more importantly, do their own investigations on the routing tables.</p><p>This was a very public BGP route leak event. It was both reported online via many news outlets and the event’s BGP data was reported via social media as it was happening. Andree Toonk tweeted a quick list of 2,400 ASNs that were affected.</p><figure class=\"kg-card kg-embed-card\"><blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">Quick dumps through the data, showing about 2400 ASns (networks) affected. Cloudflare being hit the hardest.  Top 20 of affected ASns below <a href=\"https://t.co/9J7uvyasw2\">pic.twitter.com/9J7uvyasw2</a></p>&mdash; Andree Toonk (@atoonk) <a href=\"https://twitter.com/atoonk/status/1143143943531454464?ref_src=twsrc%5Etfw\">June 24, 2019</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n</figure><p>This blog contains a large number of acronyms and those are explained at the end of the blog.</p><h3 id=\"using-ripe-ncc-archived-data\">Using RIPE NCC archived data</h3><p>The RIPE NCC operates a very useful archive of BGP routing. It runs collectors globally and provides an API for querying the data. More can be seen at <a href=\"https://stat.ripe.net/\">https://stat.ripe.net/</a>. In the world of BGP all routing is public (within the ability of anyone collecting data to have enough collections points). The archived data is very valuable for research and that’s what we will do in this blog. The site can create some very useful data visualizations.</p><p></p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"http://blog.cloudflare.com/content/images/2019/06/396531-bgplay-3.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p></p><h3 id=\"dumping-the-ripestat-data-for-this-event\">Dumping the RIPEstat data for this event</h3><p>Presently, the RIPEstat data gets ingested around eight to twelve hours after real-time. It’s not meant to be a real-time service. The data can be queried in many ways, including a full web interface and an API. We are using the API to extract the data in a JSON format. </p><p>We are going to focus only on the Cloudflare routes that were leaked. Many other ASNs were leaked (see the tweet above); however, we want to deal with a finite data set and focus on what happened to Cloudflare’s routing. All the commands below can be run with ease on many systems. Both the scripts and the raw data file are now available on <a href=\"https://github.com/cloudflare/the-deep-dive-into-how-verizon-and-a-bgp-optimizer-knocked-large-parts-of-the-internet-offline-monda\">GitHub</a>. The following was done on MacBook Pro running macOS Mojave.</p><p>First we collect 24 hours of route announcements and AS-PATH data that RIPEstat sees coming from AS13335 (Cloudflare).</p><p></p><!--kg-card-begin: markdown--><pre><code>$ # Collect 24 hours of data - more than enough\n$ ASN=&quot;AS13335&quot;\n$ START=&quot;2019-06-24T00:00:00&quot;\n$ END=&quot;2019-06-25T00:00:00&quot;\n$ ARGS=&quot;resource=${ASN}&amp;starttime=${START}&amp;endtime=${END}&quot;\n$ URL=&quot;https://stat.ripe.net/data/bgp-updates/data.json?${ARGS}&quot;\n$ # Fetch the data from RIPEstat\n$ curl -sS &quot;${URL}&quot; | jq . &gt; 13335-routes.json\n$ ls -l 13335-routes.json\n-rw-r--r--  1 martin  staff  339363899 Jun 25 08:47 13335-routes.json\n$\n</code></pre>\n<!--kg-card-end: markdown--><p></p><p>That’s 340MB of data - which seems like a lot, but it contains plenty of white space and plenty of data we just don’t need. Our second task is to reduce this raw data down to just the required data - that’s timestamps, actual routes, and AS-PATH. The third item will be very useful. Note we are using <a href=\"https://stedolan.github.io/jq/\">jq</a>, which can be installed on macOS with the  <a href=\"https://brew.sh/\">brew package manager</a>.</p><p></p><!--kg-card-begin: markdown--><pre><code>$ # Extract just the times, routes, and AS-PATH\n$ jq -rc '.data.updates[]|.timestamp,.attrs.target_prefix,.attrs.path' &lt; 13335-routes.json | paste - - - &gt; 13335-listing-a.txt\n$ wc -l 13335-listing-a.txt\n691318 13335-listing-a.txt\n$\n</code></pre>\n<!--kg-card-end: markdown--><p></p><p>We are down to just below seven hundred thousand routing events, however, that’s not a leak, that’s everything that includes Cloudflare’s ASN (the number 13335 above). For that we need to go back to Monday’s blog and realize it was AS396531 (Allegheny Technologies) that showed up with 701 (Verizon) in the leak. Now we reduce the data further:</p><p></p><!--kg-card-begin: markdown--><pre><code>$ # Extract the route leak 701,396531\n$ # AS701 is Verizon and AS396531 is Allegheny Technologies\n$ egrep '701,396531' &lt; 13335-listing-a.txt &gt; 13335-listing-b.txt\n$ wc -l 13335-listing-b.txt\n204568 13335-listing-b.txt\n$\n</code></pre>\n<!--kg-card-end: markdown--><p></p><p>At 204 thousand data points, we are looking better. It’s still a lot of data because BGP can be very chatty if topology is changing. A route leak will cause exactly that. Now let’s see how many routes were affected:</p><p></p><!--kg-card-begin: markdown--><pre><code>$ # Extract the actual routes affected by the route leak\n$ cut -f2 &lt; 13335-listing-b.txt | sort -V -u &gt; 13335-listing-c.txt\n$ wc -l 13335-listing-c.txt\n101 13335-listing-c.txt\n$\n</code></pre>\n<!--kg-card-end: markdown--><p></p><p>It’s a much smaller number. We now have a listing of at least 101 routes that were leaked via Verizon. This may not be the full list because route collectors like RIPEstat don’t have direct feeds from Verizon, so this data is a blended view with Verizon’s path and other paths. We can see that if we look at the AS-PATH in the above files. Please note that I had a typo in this script when this blog was first published and only 20 routes showed up because the -n vs -V option was used on sort. Now the list is correct with 101 affected routes. Please see this short article from <a href=\"https://stackoverflow.com/questions/42526860/bash-sort-nu-results-in-unexpected-behaviour\">stackoverflow</a> to see the issue.</p><p>Here’s a partial listing of affected routes.</p><p></p><!--kg-card-begin: markdown--><pre><code>$ cat 13335-listing-c.txt\n8.39.214.0/24\n8.42.245.0/24\n8.44.58.0/24\n...\n104.16.80.0/21\n104.17.168.0/21\n104.18.32.0/21\n104.19.168.0/21\n104.20.64.0/21\n104.22.8.0/21\n104.23.128.0/21\n104.24.112.0/21\n104.25.144.0/21\n104.26.0.0/21\n104.27.160.0/21\n104.28.16.0/21\n104.31.0.0/21\n141.101.120.0/23\n162.159.224.0/21\n172.68.60.0/22\n172.69.116.0/22\n...\n$\n</code></pre>\n<!--kg-card-end: markdown--><p></p><p>This is an interesting list, as some of these routes do not originate from Cloudflare’s network, however, they show up with AS13335 (our ASN) as the originator. For example, the 104.26.0.0/21 route is not announced from our network, but we do announce 104.26.0.0/20 (which covers that route). More importantly, we have an IRR (Internet Routing Registries) route object plus an RPKI ROA for that block. Here’s the IRR object:</p><p></p><!--kg-card-begin: markdown--><pre><code>route:          104.26.0.0/20\norigin:         AS13335\nsource:         ARIN\n</code></pre>\n<!--kg-card-end: markdown--><p></p><p>And here’s the RPKI ROA. This ROA has Max Length set to 20, so no smaller route should be accepted.</p><p></p><!--kg-card-begin: markdown--><pre><code>Prefix:       104.26.0.0/20\nMax Length:   /20\nASN:          13335\nTrust Anchor: ARIN\nValidity:     Thu, 02 Aug 2018 04:00:00 GMT - Sat, 31 Jul 2027 04:00:00 GMT\nEmitted:      Thu, 02 Aug 2018 21:45:37 GMT\nName:         535ad55d-dd30-40f9-8434-c17fc413aa99\nKey:          4a75b5de16143adbeaa987d6d91e0519106d086e\nParent Key:   a6e7a6b44019cf4e388766d940677599d0c492dc\nPath:         rsync://rpki.arin.net/repository/arin-rpki-ta/5e4a23ea-...\n</code></pre>\n<!--kg-card-end: markdown--><p></p><p>The Max Length field in an ROA says what the minimum size of an acceptable announcement is. The fact that this is a /20 route with a /20 Max Length says that a /21 (or /22 or /23 or /24) within this IP space isn’t allowed. Looking further at the route list above we get the following listing:</p><p></p><!--kg-card-begin: markdown--><pre><code>Route Seen            Cloudflare IRR &amp; ROA    ROA Max Length\n104.16.80.0/21    -&gt;  104.16.80.0/20          /20\n104.17.168.0/21   -&gt;  104.17.160.0/20         /20\n104.18.32.0/21    -&gt;  104.18.32.0/20          /20\n104.19.168.0/21   -&gt;  104.19.160.0/20         /20\n104.20.64.0/21    -&gt;  104.20.64.0/20          /20\n104.22.8.0/21     -&gt;  104.22.0.0/20           /20\n104.23.128.0/21   -&gt;  104.23.128.0/20         /20\n104.24.112.0/21   -&gt;  104.24.112.0/20         /20\n104.25.144.0/21   -&gt;  104.25.144.0/20         /20\n104.26.0.0/21     -&gt;  104.26.0.0/20           /20\n104.27.160.0/21   -&gt;  104.27.160.0/20         /20\n104.28.16.0/21    -&gt;  104.28.16.0/20          /20\n104.31.0.0/21     -&gt;  104.31.0.0/20           /20\n</code></pre>\n<!--kg-card-end: markdown--><p></p><p>So how did all these /21’s show up? That’s where we dive into the world of BGP route optimization systems and their propensity to synthesize routes that should not exist. If those routes leak (and it’s very clear after this week that they can), all hell breaks loose. That can be compounded when not one, but two ISPs allow invalid routes to be propagated outside their autonomous network. We will explore the AS-PATH further down this blog.</p><p>More than 20 years ago, <a href=\"https://tools.ietf.org/html/rfc1997\">RFC1997</a> added the concept of <em>communities</em> to BGP. Communities are a way of tagging or grouping route advertisements. Communities are often used to label routes so that specific handling policies can be applied. RFC1997 includes a small number of universal <em>well-known communities</em>. One of these is the NO_EXPORT community, which has the following specification:</p><p></p><!--kg-card-begin: markdown--><pre><code>    All routes received carrying a communities attribute\n    containing this value MUST NOT be advertised outside a BGP\n    confederation boundary (a stand-alone autonomous system that\n    is not part of a confederation should be considered a\n    confederation itself).\n</code></pre>\n<!--kg-card-end: markdown--><p></p><p>The use of the NO_EXPORT community is very common within BGP enabled networks and is a community tag that would have helped alleviate this route leak immensely. </p><p>How BGP route optimization systems work (or don’t work in this case) can be a subject for a whole other blog entry.</p><h3 id=\"timing-of-the-route-leak\">Timing of the route leak</h3><p>As we saved away the timestamps in the JSON file and in the text files, we can confirm the time for every route in the route leak by looking at the first and the last timestamp of a route in the data. We saved data from 00:00:00 UTC until 00:00:00 the next day, so we know we have covered the period of the route leak. We write a script that checks the first and last entry for every route and report the information sorted by start time:</p><p></p><!--kg-card-begin: markdown--><pre><code>$ # Extract the timing of the route leak\n$ while read cidr\ndo\n  echo $cidr\n  fgrep $cidr &lt; 13335-listing-b.txt | head -1 | cut -f1\n  fgrep $cidr &lt; 13335-listing-b.txt | tail -1 | cut -f1\ndone &lt; 13335-listing-c.txt |\\\npaste - - - | sort -k2,3 | column -t | sed -e 's/2019-06-24T//g'\n...\n104.25.144.0/21   10:34:25  12:38:54\n104.22.8.0/21     10:34:27  12:29:39\n104.20.64.0/21    10:34:27  12:30:00\n104.23.128.0/21   10:34:27  12:30:34\n141.101.120.0/23  10:34:27  12:30:39\n162.159.224.0/21  10:34:27  12:30:39\n104.18.32.0/21    10:34:29  12:30:34\n104.24.112.0/21   10:34:29  12:30:34\n104.27.160.0/21   10:34:29  12:30:34\n104.28.16.0/21    10:34:29  12:30:34\n104.31.0.0/21     10:34:29  12:30:34\n8.39.214.0/24     10:34:31  12:19:24\n104.26.0.0/21     10:34:36  12:29:53\n172.68.60.0/22    10:34:38  12:19:24\n172.69.116.0/22   10:34:38  12:19:24\n8.44.58.0/24      10:34:38  12:19:24\n8.42.245.0/24     11:52:49  11:53:19\n104.17.168.0/21   12:00:13  12:29:34\n104.16.80.0/21    12:00:13  12:30:00\n104.19.168.0/21   12:09:39  12:29:34\n...\n$\n</code></pre>\n<!--kg-card-end: markdown--><p></p><p>Now we know the times. The route leak started at 10:34:25 UTC (just before lunchtime London time) on 2019-06-24 and ended at 12:38:54 UTC. That’s a hair over two hours. Here’s that same time data in a graphical form showing the near-instant start of the event and the duration of each route leaked:</p><p></p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"http://blog.cloudflare.com/content/images/2019/06/cloudflare-via-verizon-leak-timing-1.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p></p><p>We can also go back to RIPEstat and look at the activity graph for Cloudflare’s AS13335 network:</p><p></p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"http://blog.cloudflare.com/content/images/2019/06/cloudflare-route-activity.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p></p><p>Clearly between 10:30 UTC and 12:40 UTC there’s a lot of route activity - far more than normal.</p><p>Note that as we mentioned above, RIPEstat doesn’t get a full view of Verizon’s network routing and hence some of the propagated routes won’t show up.</p><h3 id=\"drilling-down-on-the-as-path-part-of-the-data\">Drilling down on the AS-PATH part of the data</h3><p>Having the routes is useful, but now we want to look at the paths of these leaked routes to see which ASNs are involved. We knew the offending ASNs during the route leak on Monday. Now we want to dig deeper using the archived data. This allows us to see the extent and reach of this route leak.</p><!--kg-card-begin: markdown--><pre><code>$ # Extract the AS-PATH of the route leak\n$ # Use the list of routes to extract the full AS-PATH\n$ # Merge the results together to show an amalgamation of paths.\n$ # We know (luckily) the last few ASNs in the AS-PATH are consistent\n$ cut -f3 &lt; 13335-listing-b.txt | tr -d '[\\[\\]]' |\\\nawk '{\n  n=split($0, a, &quot;,&quot;);\n  printf &quot;%50s\\n&quot;,\n    a[n-5] &quot;_&quot; a[n-4] &quot;_&quot; a[n-3] &quot;_&quot; a[n-2] &quot;_&quot; a[n-1] &quot;_&quot; a[n];\n}' | sort -u\n   174_701_396531_33154_3356_13335\n   2497_701_396531_33154_174_13335\n   577_701_396531_33154_3356_13335\n   6939_701_396531_33154_174_13335\n  1239_701_396531_33154_3356_13335\n  1273_701_396531_33154_3356_13335\n  1280_701_396531_33154_3356_13335\n  2497_701_396531_33154_3356_13335\n  2516_701_396531_33154_3356_13335\n  3320_701_396531_33154_3356_13335\n  3491_701_396531_33154_3356_13335\n  4134_701_396531_33154_3356_13335\n  4637_701_396531_33154_3356_13335\n  6453_701_396531_33154_3356_13335\n  6461_701_396531_33154_3356_13335\n  6762_701_396531_33154_3356_13335\n  6830_701_396531_33154_3356_13335\n  6939_701_396531_33154_3356_13335\n  7738_701_396531_33154_3356_13335\n 12956_701_396531_33154_3356_13335\n 17639_701_396531_33154_3356_13335\n 23148_701_396531_33154_3356_13335\n$\n</code></pre>\n<!--kg-card-end: markdown--><p>This script clearly shows the AS-PATH of the leaked routes. It’s very consistent. Reading from the back of the line to the front, we have 13335 (Cloudflare), 3356 or 174 (Level3/CenturyLink or Cogent - both tier 1 transit providers for Cloudflare). So far, so good. Then we have 33154 (DQE Communications) and 396531 (Allegheny Technologies Inc) which is still technically not a leak, but trending that way. The reason why we can state this is still technically not a leak is because we don’t know the relationship between those two ASs. It’s possible they have a mutual transit agreement between them. That’s up to them.</p><p>Back to the AS-PATH’s. Still reading leftwards, we see 701 (Verizon), which is very very bad and clear evidence of a leak. It’s a leak for two reasons. First, this matches the path when a transit is leaking a non-customer route from a customer. This Verizon customer does not have 13335 (Cloudflare) listed as a customer. Second, the route contains within its path a tier 1 ASN. This is the point where a route leak should have been absolutely squashed by filtering on the customer BGP session. Beyond this point there be dragons.</p><p>And dragons there be! Everything above is about how Verizon filtered (or didn’t filter) its customer. What follows the 701 (i.e the number to the left of it) is the peers or customers of Verizon that have accepted these leaked routes. They are mainly other tier 1 networks of Verizon in this list: 174 (Cogent), 1239 (Sprint), 1273 (Vodafone), 3320 (DTAG), 3491 (PCCW), 6461 (Zayo), 6762 (Telecom Italia), etc.</p><p>What’s missing from that list are three networks worthy of mentioning - 1299 (Telia), 2914 (NTT), and 7018 (AT&amp;T). All three implement a very simple AS-PATH filter which saved the day for their network. They do not allow one tier 1 ISP to send them a route which has another tier 1 further down the path. That’s because when that happens, it’s officially a leak as each tier 1 is fully connected to all other tier 1’s (which is part of the definition of a tier 1 network). The topology of the Internet’s global BGP routing tables simply states that if you see another tier 1 in the path, then it’s a bad route and it should be filtered away.</p><p>Additionally we know that 7018 (AT&amp;T) operates a network which drops RPKI invalids. Because Cloudflare routes are <a href=\"http://blog.cloudflare.com/rpki-details/\">RPKI signed</a>, this also means that AT&amp;T would have dropped these routes when it receives them from Verizon. This shows a clear win for RPKI (and for AT&amp;T when you see their bandwidth graph below)!</p><p></p><figure class=\"kg-card kg-embed-card\"><blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">BREAKING - AT&amp;T / AS 7018 is now rejecting RPKI Invalid BGP announcements they receive from their peering partners. This is big news for routing security! If AT&amp;T can do it - you can do it! :-) <a href=\"https://t.co/FhjmWByagO\">https://t.co/FhjmWByagO</a></p>&mdash; Job Snijders (@JobSnijders) <a href=\"https://twitter.com/JobSnijders/status/1094976832267522048?ref_src=twsrc%5Etfw\">February 11, 2019</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n</figure><p></p><p>That all said, keep in mind we are still talking about routes that Cloudflare didn't announce. They all came from the route optimizer.</p><h3 id=\"what-should-701-verizon-network-accept-from-their-customer-396531\">What should 701 Verizon network accept from their customer 396531?</h3><p>This is a great question to ask. Normally we would look at the IRR (Internet Routing Registries) to see what policy an ASN wants for it’s routes.</p><p></p><!--kg-card-begin: markdown--><pre><code>$ whois -h whois.radb.net AS396531 ; the Verizon customer\n%  No entries found for the selected source(s).\n$ whois -h whois.radb.net AS33154  ; the downstream of that customer\n%  No entries found for the selected source(s).\n$ \n</code></pre>\n<!--kg-card-end: markdown--><p></p><p>That’s enough to say that we should not be seeing this ASN anywhere on the Internet, however, we should go further into checking this. As we know the ASN of the network, we can search for any routes that are listed for that ASN. We find one:</p><p></p><!--kg-card-begin: markdown--><pre><code>$ whois -h whois.radb.net ' -i origin AS396531' | egrep '^route|^origin|^mnt-by|^source'\nroute:          192.92.159.0/24\norigin:         AS396531\nmnt-by:         MNT-DCNSL\nsource:         ARIN\n$\n</code></pre>\n<!--kg-card-end: markdown--><p></p><p>More importantly, now we have a maintainer (the owner of the routing registry entries). We can see what else is there for that network and we are specifically looking for this:</p><p></p><!--kg-card-begin: markdown--><pre><code>$ whois -h whois.radb.net ' -i mnt-by -T as-set MNT-DCNSL' | egrep '^as-set|^members|^mnt-by|^source'\nas-set:         AS-DQECUST\nmembers:        AS4130, AS5050, AS11199, AS11360, AS12017, AS14088, AS14162,\n                AS14740, AS15327, AS16821, AS18891, AS19749, AS20326,\n                AS21764, AS26059, AS26257, AS26461, AS27223, AS30168,\n                AS32634, AS33039, AS33154, AS33345, AS33358, AS33504,\n                AS33726, AS40549, AS40794, AS54552, AS54559, AS54822,\n                AS393456, AS395440, AS396531, AS15204, AS54119, AS62984,\n                AS13659, AS54934, AS18572, AS397284\nmnt-by:         MNT-DCNSL\nsource:         ARIN\n$\n</code></pre>\n<!--kg-card-end: markdown--><p></p><p>This object is important. It lists all the downstream ASNs that this network is expected to announce to the world. It does not contain Cloudflare’s ASN (or any of the leaked ASNs). Clearly this as-set was not used for any BGP filtering.</p><p>Just for completeness the same exercise can be done for the other ASN (the downstream of the customer of Verizon). In this case, we just searched for the maintainer object (as there are plenty of route and route6 objects listed).</p><p></p><!--kg-card-begin: markdown--><pre><code>$ whois -h whois.radb.net ' -i origin AS33154' | egrep '^mnt-by' | sort -u\nmnt-by:         MNT-DCNSL\nmnt-by:     MAINT-AS3257\nmnt-by:     MAINT-AS5050\n$\n</code></pre>\n<!--kg-card-end: markdown--><p></p><p>None of these maintainers are directly related to 33154 (DQE Communications). They have been created by other parties and hence they become a dead-end in that search.</p><p>It’s worth doing a secondary search to see if any as-set object exists with 33154 or 396531 included. We turned to the most excellent <a href=\"http://irrexplorer.nlnog.net/\">IRR Explorer</a> website run by NLNOG. It provides deep insight into the routing registry data. We did a simple search for 33154 using <a href=\"http://irrexplorer.nlnog.net/search/33154\">http://irrexplorer.nlnog.net/search/33154</a> and we found these as-set objects.</p><p></p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"http://blog.cloudflare.com/content/images/2019/06/as-set-containing-as33154.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p></p><p>It’s interesting to see this ASN listed in other as-set’s but none are important or related to Monday’s route-leak. Next we looked at 396531</p><p></p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"http://blog.cloudflare.com/content/images/2019/06/as-set-containing-as396531.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p></p><p>This shows that there’s nowhere else we need to check. AS-DQECUST is the as-set macro that controls (or should control) filtering for any transit provider of their network.</p><p>The summary of all the investigation is a solid statement that no Cloudflare routes or ASNs are listed anywhere within the routing registry data for the customer of Verizon. As there were 2,300 ASNs listed in the tweet above, we can conclusively state no filtering was in place and hence this route leak went on its way unabated.</p><h3 id=\"ipv6-where-is-the-ipv6-route-leak\">IPv6? Where is the IPv6 route leak?</h3><p>In what could be considered the only plus from Monday’s route leak, we can confirm that there was no route leak within IPv6 space. Why?</p><p>It turns out that 396531 (Allegheny Technologies Inc) is a network without IPv6 enabled. Normally you would hear Cloudflare chastise anyone that’s yet to enable IPv6, however, in this case we are quite happy that one of the two protocol families survived. IPv6 was stable during this route leak, which now can be called an IPv4-only route leak.</p><p>Yet that’s not really the whole story. Let’s look at the percentage of traffic Cloudflare sends Verizon that’s IPv6 (vs IPv4). Normally the IPv4/IPv6 percentage holds steady.</p><p></p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"http://blog.cloudflare.com/content/images/2019/06/verizon-ipv6-percentage.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p></p><p>This uptick in IPv6 traffic could be the direct result of Happy Eyeballs on mobile handsets picking a working IPv6 path into Cloudflare vs a non-working IPv4 path. Happy Eyeballs is meant to protect against IPv6 failure, however in this case it’s doing a wonderful job in protecting from an IPv4 failure. Yet we have to be careful with this graph because after further thought and investigation the percentage only increased because IPv4 reduces. Sometimes graphs can be misinterpreted, yet Happy Eyeballs still did a good job even as end users were being affected.</p><p>Happy Eyeballs, described in <a href=\"https://tools.ietf.org/html/rfc8305\">RFC8305</a>, is a mechanism where a client (lets say a mobile device) tries to connect to a website both on IPv4 and IPv6 simultaneously. IPv6 is sometimes given a head-start. The theory is that, should a failure exist on one of the paths (sadly IPv6 is the norm), then IPv4 will save the day. Monday was a day of opposites for Verizon.</p><p>In fact, enabling IPv6 for mobile users is the one area where we can praise the Verizon network this week (or at least the Verizon mobile network), unlike the residential Verizon networks where IPv6 is almost non-existent.</p><h3 id=\"using-bandwidth-graphs-to-confirm-routing-leaks-and-stability-\">Using bandwidth graphs to confirm routing leaks and stability.</h3><p>As we have already stated,Verizon had impacted their own users/customers. Let’s start with their bandwidth graph:</p><p></p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"http://blog.cloudflare.com/content/images/2019/06/verizon-bandwidth.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p></p><p>The red line is 24 June 2019 (00:00 UTC to 00:00 UTC the next day). The gray lines are previous days for comparison. This graph includes both Verizon fixed-line services like FiOS along with mobile.</p><p>The AT&amp;T graph is quite different.</p><p></p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"http://blog.cloudflare.com/content/images/2019/06/att-bandwidth.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p></p><p>There’s no perturbation. This, along with some direct confirmation, shows that 7018 (AT&amp;T) was not affected. This is an important point.</p><p>Going back and looking at a third tier 1 network, we can see 6762 (Telecom Italia) affected by this route leak and yet Cloudflare has a direct interconnect with them.</p><p></p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"http://blog.cloudflare.com/content/images/2019/07/telecomitalia-bandwidth.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p></p><p>We will be asking Telecom Italia to improve their route filtering as we now have this data.</p><h3 id=\"future-work-that-could-have-helped-on-monday\">Future work that could have helped on Monday</h3><p>The IETF is doing work in the area of BGP path protection within the <a href=\"https://datatracker.ietf.org/wg/sidrops/about/\">Secure Inter-Domain Routing Operations Working Group</a> (sidrops) area. The charter of this IETF group is:</p><blockquote>The SIDR Operations Working Group (sidrops) develops guidelines for the operation of SIDR-aware networks, and provides operational guidance on how to deploy and operate SIDR technologies in existing and new networks.</blockquote><p>One new effort from this group should be called out to show how important the issue of route leaks like today’s event is. The draft document from Alexander Azimov et al named <a href=\"https://tools.ietf.org/html/draft-ietf-sidrops-aspa-profile-00\">draft-ietf-sidrops-aspa-profile</a> (ASPA stands for Autonomous System Provider Authorization) extends the RPKI data structures to handle BGP path information. This in ongoing work and Cloudflare and other companies are clearly interested in seeing it progress further.</p><p>However, as we said in Monday’s blog and something we should reiterate again and again: Cloudflare encourages all network operators to <a href=\"http://blog.cloudflare.com/rpki-details/\">deploy RPKI</a> now!</p><h3 id=\"acronyms-used-in-the-blog\">Acronyms used in the blog</h3><!--kg-card-begin: markdown--><ul>\n<li>API - Application Programming Interface</li>\n<li>AS-PATH - The list of ASNs that a routes has traversed so far</li>\n<li>ASN - Autonomous System Number - A unique number assigned for each network on the Internet</li>\n<li>BGP - Border Gateway Protocol (version 4) - the core routing protocol for the Internet</li>\n<li>IETF - Internet Engineering Task Force - an open standards organization</li>\n<li>IPv4 - Internet Protocol version 4</li>\n<li>IPv6 - Internet Protocol version 6</li>\n<li>IRR - Internet Routing Registries - a database of Internet route objects</li>\n<li>ISP - Internet Service Provider</li>\n<li>JSON - JavaScript Object Notation - a lightweight data-interchange format</li>\n<li>RFC - Request For Comment - published by the IETF</li>\n<li>RIPE NCC - Réseaux IP Européens Network Coordination Centre - a regional Internet registry</li>\n<li>ROA - Route Origin Authorization - a cryptographically signed attestation of a BGP route announcement</li>\n<li>RPKI - Resource Public Key Infrastructure - a public key infrastructure framework for routing information</li>\n<li>Tier 1 - A network that has no default route and peers with all other tier 1's</li>\n<li>UTC - Coordinated Universal Time - a time standard for clocks and time</li>\n<li>&quot;there be dragons&quot; - a mistype, as it was meant to be &quot;<a href=\"https://en.wikipedia.org/wiki/Here_be_dragons\">here be dragons</a>&quot; which means dangerous or unexplored territories</li>\n</ul>\n<!--kg-card-end: markdown-->",
		"id": "5d16453b41acde0011a95874",
		"meta_description": null,
		"meta_title": null,
		"og_description": null,
		"og_image": null,
		"og_title": null,
		"primary_author": {
			"id": "5d1644b141acde0011a94f36",
			"name": "Martin J Levy",
			"slug": "martin-levy",
			"profile_image": "https://blog-cloudflare-com-assets.storage.googleapis.com/2019/07/A03361C5-7DAD-4D01-8A98-A1400DF38E31.jpeg",
			"cover_image": "http://blog.cloudflare.com/content/images/2018/08/general@2x-102.png",
			"bio": null,
			"website": null,
			"location": null,
			"facebook": null,
			"twitter": "@mahtin",
			"meta_title": null,
			"meta_description": null,
			"url": "http://blog.cloudflare.com/author/martin-levy/"
		},
		"primary_tag": {
			"id": "5d16450341acde0011a95274",
			"name": "RPKI",
			"slug": "rpki",
			"description": null,
			"feature_image": null,
			"visibility": "public",
			"meta_title": null,
			"meta_description": null,
			"og_image": null,
			"og_title": null,
			"og_description": null,
			"twitter_image": null,
			"twitter_title": null,
			"twitter_description": null,
			"codeinjection_head": null,
			"codeinjection_foot": null,
			"canonical_url": null,
			"accent_color": null,
			"url": "http://blog.cloudflare.com/tag/rpki/"
		},
		"published_at": "2019-06-26T23:22:13.000+01:00",
		"reading_time": 17,
		"slug": "the-deep-dive-into-how-verizon-and-a-bgp-optimizer-knocked-large-parts-of-the-internet-offline-monday",
		"tags": [
			{
				"id": "5d16450341acde0011a95274",
				"name": "RPKI",
				"slug": "rpki",
				"description": null,
				"feature_image": null,
				"visibility": "public",
				"meta_title": null,
				"meta_description": null,
				"og_image": null,
				"og_title": null,
				"og_description": null,
				"twitter_image": null,
				"twitter_title": null,
				"twitter_description": null,
				"codeinjection_head": null,
				"codeinjection_foot": null,
				"canonical_url": null,
				"accent_color": null,
				"url": "http://blog.cloudflare.com/tag/rpki/"
			},
			{
				"id": "5d16450341acde0011a95151",
				"name": "BGP",
				"slug": "bgp",
				"description": null,
				"feature_image": null,
				"visibility": "public",
				"meta_title": null,
				"meta_description": null,
				"og_image": null,
				"og_title": null,
				"og_description": null,
				"twitter_image": null,
				"twitter_title": null,
				"twitter_description": null,
				"codeinjection_head": null,
				"codeinjection_foot": null,
				"canonical_url": null,
				"accent_color": null,
				"url": "http://blog.cloudflare.com/tag/bgp/"
			},
			{
				"id": "5d16450341acde0011a9531b",
				"name": "Deep Dive",
				"slug": "deep-dive",
				"description": null,
				"feature_image": "http://blog.cloudflare.com/content/images/2023/08/CloudflareBlog-DeepDive.png",
				"visibility": "public",
				"meta_title": "Cloudflare Blog: Deep Dive",
				"meta_description": "Collection of Cloudflare blog posts tagged 'Deep Dive'.",
				"og_image": null,
				"og_title": null,
				"og_description": null,
				"twitter_image": null,
				"twitter_title": null,
				"twitter_description": null,
				"codeinjection_head": null,
				"codeinjection_foot": null,
				"canonical_url": null,
				"accent_color": null,
				"url": "http://blog.cloudflare.com/tag/deep-dive/"
			},
			{
				"id": "5d16450341acde0011a95150",
				"name": "Post Mortem",
				"slug": "post-mortem",
				"description": null,
				"feature_image": null,
				"visibility": "public",
				"meta_title": null,
				"meta_description": null,
				"og_image": null,
				"og_title": null,
				"og_description": null,
				"twitter_image": null,
				"twitter_title": null,
				"twitter_description": null,
				"codeinjection_head": null,
				"codeinjection_foot": null,
				"canonical_url": null,
				"accent_color": null,
				"url": "http://blog.cloudflare.com/tag/post-mortem/"
			}
		],
		"title": "The deep-dive into how Verizon and a BGP Optimizer Knocked Large Parts of the Internet Offline Monday",
		"twitter_description": null,
		"twitter_image": null,
		"twitter_title": null,
		"updated_at": "2019-07-14T23:09:15.000+01:00",
		"url": "http://blog.cloudflare.com/the-deep-dive-into-how-verizon-and-a-bgp-optimizer-knocked-large-parts-of-the-internet-offline-monday/",
		"uuid": "cb488855-4056-455c-9d9e-ab6ba5b35331",
		"visibility": "public"
	}
}