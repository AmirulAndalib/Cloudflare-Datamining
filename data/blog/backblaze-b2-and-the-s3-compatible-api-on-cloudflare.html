<div class="mb2 gray5">5 min read</div>
<div class="post-content lh-copy gray1">
	<p>In May 2020, Backblaze, a founding Bandwidth Alliance partner announced <a href="https://www.backblaze.com/blog/backblaze-b2-s3-compatible-api">S3 compatible APIs</a> for their B2 Cloud Storage service. As a refresher, the <a href="https://blog.cloudflare.com/bandwidth-alliance">Bandwidth Alliance</a> is a group of forward-thinking cloud and networking companies that are committed to discounting or waiving data transfer fees for shared customers. Backblaze has been a proud partner since 2018. We are excited to see Backblaze introduce a new level of compatibility in their Cloud Storage service.</p>
	<h3 id="history-of-the-s3-api">History of the S3 API</h3>
	<p>First letâ€™s dive into the history of the S3 API and why itâ€™s important for Cloudflare users.</p>
	<p>Prior to 2006, before the mass migration to the Cloud, if you wanted to store content for your company you needed to build your own expensive and highly available storage platform that was large enough to store all your existing content with enough growth headroom for your business. AWS launched to help eliminate this model by renting their physical computing and storage infrastructure.</p>
	<p>Amazon Simple Storage Service (S3) led the market by offering a scalable and resilient tool for storing unlimited amounts of data without building it yourself. It could be integrated into any application but there was one catch: you couldnâ€™t use any existing standard such as WebDAV, FTP or SMB: your application needed to interface with Amazonâ€™s bespoke S3 API.</p>
	<p>Fast forward to 2020 and the storage provider landscape has become highly competitive with many providers capable of providing petabyte (and exabyte) scale content storage at extremely low cost-per-gigabyte. However, Amazon S3 has remained a dominant player despite heavy competition and not being the most cost-effective player.</p>
	<p>The broad adoption of the S3 API by developers in their codebases and internal systems has transformed the S3 API into what WebDAV promised us to be: de facto standard HTTP File Storage API.</p>
	<h3 id="engineering-costs-of-changing-storage-providers">Engineering costs of changing storage providers</h3>
	<p>With many code bases and legacy applications being entrenched in the S3 API, the process to switch to a more cost-effective storage provider is not so easy. Companies need to consider the cost of engineer time programming a new storage API while also physically moving their data.</p>
	<p>This engineering overhead has led many storage providers to natively support the S3 API, leveling the playing field and allowing companies to focus on picking the most cost-effective provider.</p>
	<h3 id="first-mile-bandwidth-costs-and-the-bandwidth-alliance">First-mile bandwidth costs and the Bandwidth Alliance</h3>
	<p>Cloudflare caches content in Points of Presence located in more than 200 cities around the world. This cached content is then handed to your Internet service provider (ISP) over low cost and often free Internet exchange connections in the same facility using mutual fibre optic cables. This cost saving is fairly well understood as the benefit of content delivery networks and has become highly commoditized.</p>
	<p>What is less well understood is the <em>first-mile</em> cost of moving data from a storage provider to the content delivery network. Typically storage providers expect traffic to route via the Internet and will charge the consumer per-gigabyte of data transmitted. This is not the case for Cloudflare as we also share facilities and mutual fibre optic cables with many storage providers.</p>
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2020/05/image2-3.png" class="kg-image" alt="" loading="lazy"></figure>
	<p>These shared interconnects created an opportunity to waive the cost of first-mile bandwidth between Cloudflare and many providers and is what prompted us to create the Bandwidth Alliance.</p>
	<p>Media and entertainment companies serving user-generated content have a continuous supply of new content being moved over the first-mile from the storage provider to the content delivery network. The first-mile bandwidth cost adds up and using a Bandwidth Alliance partner such Backblaze can entirely eliminate it.</p>
	<h3 id="using-the-s3-api-in-cloudflare-workers">Using the S3 API in Cloudflare Workers</h3>
	<p>The Solutions Engineering team at Cloudflare is tasked with providing strategic technical guidance for our enterprise customers.</p>
	<p>Itâ€™s not uncommon for developers to connect Cloudflareâ€™s global network directly to their storage provider and directly serve content such as live and on-demand video without an intermediate web server.</p>
	<p>For security purposes engineers typically use Cloudflare Workers to sign each uncached request using the S3 API. Cloudflare Workers allows anyone to deploy code to our global network of over 200+ Points of Presence in seconds and is built on top of Service Workers.</p>
	<p>Weâ€™ve tested Backblaze B2â€™s S3 Compatible API in Cloudflare Workers using the same code tested for Amazon S3 buckets and it works perfectly by changing the target endpoint.</p>
	<h3 id="creating-a-s3-compatible-worker-script">Creating a S3 Compatible Worker script</h3>
	<p>Hereâ€™s how it is done using Cloudflare Workerâ€™s CLI tool <a href="https://developers.cloudflare.com/workers/quickstart#installing-the-cli">Wrangler</a>:</p>
	<p>Generate a new project in Wrangler using a template intended for use with Amazon S3:</p><!--kg-card-begin: markdown-->
	<pre><code class="language-javascript">wrangler generate &lt;projectname&gt; https://github.com/obezuk/worker-signed-s3-template</code></pre>
	<!--kg-card-end: markdown-->
	<p>This template uses <a href="https://github.com/mhart/aws4fetch">aws4fetch</a>. A fast, lightweight implementation of an S3 Compatible signing library that is commonly used in Service Worker environments like Cloudflare Workers.</p>
	<p>The template creates an index.js file with a standard request signing implementation:</p><!--kg-card-begin: markdown-->
	<pre><code class="language-javascript">import { AwsClient } from 'aws4fetch'

const aws = new AwsClient({
    "accessKeyId": AWS_ACCESS_KEY_ID,
    "secretAccessKey": AWS_SECRET_ACCESS_KEY,
    "region": AWS_DEFAULT_REGION
});

addEventListener('fetch', function(event) {
    event.respondWith(handleRequest(event.request))
});

async function handleRequest(request) {
    var url = new URL(request.url);
    url.hostname = AWS_S3_BUCKET;
    var signedRequest = await aws.sign(url);
    return await fetch(signedRequest, { "cf": { "cacheEverything": true } });
}</code></pre>
	<!--kg-card-end: markdown-->
	<h3 id="environment-variables">Environment Variables</h3>
	<p>Modify your wrangler.toml file to use your Backblaze B2 API Key ID and Secret:</p><!--kg-card-begin: markdown-->
	<pre><code class="language-javascript">[env.dev]
vars = { AWS_ACCESS_KEY_ID = "&lt;BACKBLAZE B2 keyId&gt;", 
AWS_SECRET_ACCESS_KEY = "&lt;BACKBLAZE B2 secret&gt;", 
AWS_DEFAULT_REGION = "", 
AWS_S3_BUCKET = "&lt;BACKBLAZE B2 bucketName&gt;.&lt;BACKBLAZE B2 S3 Endpoint&gt;"}</code></pre>
	<!--kg-card-end: markdown-->
	<p><code>AWS_S3_BUCKET</code> environment variable will be the combination of your bucket name, period and S3 Endpoint. For a Backblaze B2 Bucket named <code>example-bucket</code> and S3 Endpoint <code>s3.us-west-002.backblazeb2.com</code> use <code>example-bucket.s3.us-west-002.backblazeb2.com</code></p>
	<p><code>AWS_DEFAULT_REGION</code> environment variable is interpreted from your S3 Endpoint. I use <code>us-west-002</code>.</p>
	<p>We recommend using <a href="https://developers.cloudflare.com/workers/tooling/wrangler/secrets">Secret Environment</a> variables to store your <code>AWS_SECRET_ACCESS_KEY</code> content when using this script in production.</p>
	<h3 id="preview-your-cloudflare-worker">Preview your Cloudflare Worker</h3>
	<p>Next run <code>wrangler preview --env dev</code> to enter a preview window of your Worker script. My bucket contained a static website containing adaptive streaming video content stored in a Backblaze B2 bucket.</p>
	<figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.cloudflare.com/content/images/2020/05/image1-3.png" class="kg-image" alt="" loading="lazy">
		<figcaption><em>Note: We permit caching of third party video content only for enterprise domains. Free/Pro/Biz users wanting to serve video content via Cloudflare may use </em><a href="https://www.cloudflare.com/products/cloudflare-stream"><em>Stream</em></a><em> which delivers an end-to-end video delivery service.</em></figcaption>
	</figure>
	<p>Backblaze B2â€™s compatibility for the S3 API is an exciting update that has made their storage platform highly compatible with existing code bases and legacy systems. And, as a special offer to Cloudflare blog readers, Backblaze will pay the migration costs for transferring your data from S3 to Backblaze B2 (<a href="https://hub.backblaze.com/bandwidth-alliance-summerswitch2020">click here for more detail</a>). With the cost of migration covered and compatibility for your existing workflows, it is now easier than ever to switch to a Bandwidth Alliance partner and save on first-mile costs. By doing so, you can slash your cloud bills, gain flexibility, and make no compromises to your performance.</p>
	<p>To learn more, <a href="https://www.brighttalk.com/webcast/14807/405472">join us on May 14th</a> for a webinar focused on getting you ultra fast worldwide content delivery.</p>
</div>