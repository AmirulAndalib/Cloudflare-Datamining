<div class="mb2 gray5">6 min read</div>
<div class="mt4">This post is also available in <a href="https://blog.cloudflare.com/zh-cn/cloudflares-annual-founders-letter-2023">简体中文</a>, <a href="https://blog.cloudflare.com/fr-fr/cloudflares-annual-founders-letter-2023">Français</a>, <a href="https://blog.cloudflare.com/de-de/cloudflares-annual-founders-letter-2023">Deutsch</a>, <a href="https://blog.cloudflare.com/ja-jp/cloudflares-annual-founders-letter-2023">日本語</a>, <a href="https://blog.cloudflare.com/ko-kr/cloudflares-annual-founders-letter-2023">한국어</a>, <a href="https://blog.cloudflare.com/es-es/cloudflares-annual-founders-letter-2023">Español</a> and <a href="https://blog.cloudflare.com/zh-tw/cloudflares-annual-founders-letter-2023">繁體中文</a>.</div>
<div class="post-content lh-copy gray1">
	<p></p>
	<figure class="kg-card kg-image-card ">

		<img src="https://cf-assets.www.cloudflare.com/slt3lc6tev37/67OiVANFpoXiW5HSigsJXf/8c8da12b677c38806b76b99df295d2d2/Founders--Letter-2.png" alt="" class="kg-image" width="1800" height="1013" loading="lazy">

	</figure>
	<p>Cloudflare is officially a teenager. We launched on September 27, 2010. Today we celebrate our thirteenth birthday. As is our tradition, we use the week of our birthday to launch products that we think of as our gift back to the Internet. More on some of the incredible announcements in a second, but we wanted to start by talking about something more fundamental: our identity.</p>
	<figure class="kg-card kg-image-card ">

		<img src="https://cf-assets.www.cloudflare.com/slt3lc6tev37/4fdonv6sU0NR22ONAvY8Nf/313db604ea278def862da0a3ab3e57cc/Untitled-2.png" alt="" class="kg-image" width="1200" height="432" loading="lazy">

	</figure>
	<p>Like many kids, it took us a while to fully understand who we are. We chafed at being put in boxes. People would describe Cloudflare as a security company, and we'd say, "That's not all we do." They'd say we were a network, and we'd object that we were so much more. Worst of all, they'd sometimes call us a "CDN," and we'd remind them that caching is a part of any sensibly designed system, but it shouldn't be a feature unto itself. Thank you very much.</p>
	<p>And so, yesterday, the day before our thirteenth birthday, we announced to the world finally what we realized we are: a connectivity cloud.</p>
	<h3>The connectivity cloud</h3>
	<p>What does that mean? "Connectivity" means we measure ourselves by connecting people and things together. Our job isn't to be the final destination for your data, but to help it move and flow. Any application, any data, anyone, anywhere, anytime — that's the essence of connectivity, and that’s always been the promise of the Internet.</p>
	<p>"Cloud" means the batteries are included. It scales with you. It’s programmable. Has consistent security built in. It’s intelligent and learns from your usage and others' and optimizes for outcomes better than you ever could on your own.</p>
	<figure class="kg-card kg-image-card ">

		<img src="https://cf-assets.www.cloudflare.com/slt3lc6tev37/5vtrLo5x2vMruQ6lphoUTm/a39a8d94d324c8f5b582baa6ee148b69/Untitled--1--1.png" alt="" class="kg-image" width="1200" height="411" loading="lazy">

	</figure>
	<p>Our connectivity cloud is worth contrasting against some other clouds. The so-called hyperscale public clouds are, in many ways, the opposite. They optimize for hoarding your data. Locking it in. Making it difficult to move. They are captivity clouds. And, while they may be great for some things, their full potential will only truly be unlocked for customers when combined with a connectivity cloud that lets you mix and match the best of each of their features.</p>
	<h3>Enabling the future</h3>
	<p>That's what we're seeing from the hottest startups these days. Many of the leading AI companies are using Cloudflare's connectivity cloud to move their training data to wherever there's excess GPU capacity. We estimate that across the AI startup ecosystem, Cloudflare is the most commonly used cloud provider. Because, if you're building the future, you know connectivity and the agility of the cloud are key.</p>
	<p>We've spent the last year listening to our AI customers and trying to understand what the future of AI will look like and how we can better help them build it. Today, we're releasing a series of products and features borne of those conversations and opening incredible new opportunities.</p>
	<p>The biggest opportunity in <a href="https://www.cloudflare.com/learning/ai/what-is-artificial-intelligence">AI</a> is inference. Inference is what happens when you type a prompt to write a poem about your love of connectivity clouds into ChatGPT and, seconds later, get a coherent response. Or when you run a search for a picture of your passport on your phone, and it immediately pulls it up.</p>
	<figure class="kg-card kg-image-card ">

		<img src="https://cf-assets.www.cloudflare.com/slt3lc6tev37/3hZTnf3ox43UTTLSCoQYoi/0a7f7766da472e36902be99f26d67d97/Untitled--2--1.png" alt="" class="kg-image" width="1200" height="392" loading="lazy">

	</figure>
	<p>The models that power those modern miracles take significant time to generate — a process called training. Once trained though, they can have new data fed through them over and over to generate valuable new output.</p>
	<h3>Where inference happens</h3>
	<p>Before today, those models could run in two places. The first was the end user's device — like in the case of the search for “passport” in the photos on your phone. When that's possible it's great. It's fast. Your private data stays local. And it works even when there's no network access. But it's also challenging. Models are big and the storage on your phone or other local device is limited. Moreover, putting the fastest GPU resources to process these models in your phone makes the phone expensive and burns precious battery resources.</p>
	<p>The alternative has been the centralized public cloud. This is what’s used for a big model like OpenAI’s GPT-4, which runs services like ChatGPT. But that has its own challenges. Today, nearly all the GPU resources for AI are deployed in the US — a fact that rightfully troubles the rest of the world. As AI queries get more personal, sending them all to some centralized cloud is a potential security and data locality disaster waiting to happen. Moreover, it's inherently slow and less efficient and therefore more costly than running the inference locally.</p>
	<h3>A third place for inference</h3>
	<p>Running on the device is too small. Running on the centralized public cloud is too far. It’s like the story of “Goldilocks and the Three Bears”: the right answer is somewhere in between. That's why today we're excited to be rolling out modern GPU resources across Cloudflare's global connectivity cloud. The third place for AI inference. Not too small. Not too far. The perfect step in between. By the end of the year, you'll be able to run AI models in more than 100 cities in 40+ countries where Cloudflare operates. By the end of 2024, we plan to have inference-tuned GPUs deployed in nearly every city that makes up Cloudflare's global network and within milliseconds of nearly every device connected to the Internet worldwide.</p>
	<figure class="kg-card kg-image-card ">

		<img src="https://cf-assets.www.cloudflare.com/slt3lc6tev37/fVvmxz6QyAagRfc7jnKlL/6133758f11c62d60e4a5e33e48ee42a5/Untitled--3--1.png" alt="" class="kg-image" width="1200" height="501" loading="lazy">

	</figure>
	<p>(A brief shout out for the Cloudflare team members who are, as of this moment, literally dragging suitcases full of NVIDIA GPU cards around the world and installing them in the servers that make up our network worldwide. It takes a lot of atoms to move all the bits that we do, and it takes intrepid people spanning the globe to update our network to facilitate these new capabilities.)</p>
	<p>Running AI in a connectivity cloud like Cloudflare gives you the best of both worlds: nearly boundless resources running locally near any device connected to the Internet. And we've made it flexible to run whatever models a developer creates, easy to use without needing a dev ops team, and inexpensive to run where you only pay for when we're doing inference work for you.</p>
	<p>To make this tangible, think about a Cloudflare customer that makes consumer wearable devices. They make devices that need to be smart but also affordable and have the longest possible battery life. As explorers rely on them literally to navigate out of harrowing conditions, tradeoffs aren't an option. That's why, when they heard about Cloudflare Workers AI, they immediately knew it was something they needed to try. The promise is powerful devices that are still affordable and have great battery life while still respecting users’ privacy and security.</p>
	<p>They are one of the limited set of customers we gave an early sneak peek to, all of whom immediately started running off ideas of what they could do next and clamoring to get more access. We feel like we’ve seen it and are here to report: the not-so-distant future is super cool.</p>
	<h3>The spirit of helping build a better Internet</h3>
	<p>Over the years we've announced several things on our birthday that have gone on to change the future of the Internet. On our <a href="https://blog.cloudflare.com/introducing-cloudflares-automatic-ipv6-gatewa">first birthday</a>, we announced an IPv6 gateway that has helped the Internet scale past its early protocol decisions. On our <a href="https://blog.cloudflare.com/introducing-universal-ssl">fourth birthday</a>, we announced that we were making encryption free and doubled the size of the encrypted web in a day. On our <a href="https://blog.cloudflare.com/code-everywhere-cloudflare-workers">seventh birthday</a>, we launched the Workers platform that has revolutionized how modern applications are developed. <a href="https://blog.cloudflare.com/introducing-r2-object-storage">On our eleventh birthday</a> we announced R2 and further freed data from the captivity clouds.</p>
	<figure class="kg-card kg-image-card ">

		<img src="https://cf-assets.www.cloudflare.com/slt3lc6tev37/2Zu0yp9b8e6WiwtsfH8GFM/c4495c03bbab478dceec87f5c2a1992c/Untitled--4--1.png" alt="" class="kg-image" width="1200" height="505" loading="lazy">

	</figure>
	<p>This year, as we celebrate Cloudflare's thirteenth birthday, we set out to have as dramatic an impact on AI development as we have in other areas we've focused on in the past: providing tools that bring affordable, powerful AI inference to anyone, anywhere on Earth.</p>
	<h3>Closing with a poem</h3>
	<p>And so, to commemorate that, let's close with a poem about the connectivity cloud. This one was generated using a tiny bit of code and Meta's Llama 2 <a href="https://www.cloudflare.com/learning/ai/what-is-large-language-model">LLM model</a> running on Cloudflare's Workers AI platform in a data center not far from where we're writing this…</p>
	<p><code><i>Prompt: “Write a poem that talks about the connectivity cloud and contrast it with the captivity cloud”</i></code></p>
	<p>The connectivity cloud, a wondrous sight to see,Where data flows and knowledge is set free,A place where minds meet and ideas take flight,A world of endless possibility in sight.</p>
	<p>But then there's the captivity cloud, a darker place,Where thoughts are trapped and minds are in disgrace,A prison of the mind, where freedom's lost,A world of endless sorrow and cost.</p>
	<p>So let us choose the connectivity cloud,And let our minds be free and allowed,To soar and glide and reach for the sky,And never be held back, but always fly.</p>
	<figure class="kg-card kg-image-card ">

		<img src="https://cf-assets.www.cloudflare.com/slt3lc6tev37/3aZzQ7Vw4G69UGP0rGcepY/65e9c9953267febd8e2b913018b91c6a/Screenshot-2023-09-27-at-09.54.04.png" alt="" class="kg-image" width="1618" height="262" loading="lazy">

	</figure>
	<figure class="kg-card kg-image-card ">

		<img src="https://cf-assets.www.cloudflare.com/slt3lc6tev37/6SI9dzaeXO0iBoPxQNDdh5/e0d4268f1a469d4d7ff77f8684c01045/Untitled--5-.png" alt="" class="kg-image" width="1200" height="356" loading="lazy">

	</figure>
	<p></p>
</div>