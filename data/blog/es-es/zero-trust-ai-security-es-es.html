<div class="mb2 gray5 ">8 min de lectura</div>
<div class="post-content lh-copy gray1">
	<p><strong>Conjunto de herramientas de Cloudflare One para ayudar a tus equipos a utilizar los servicios de IA de forma segura</strong></p>
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2023/05/image1-18.png" class="kg-image" alt="Zero Trust Security for AI" loading="lazy" width="1801" height="1013"></figure>
	<p>Cloudflare One ofrece a todos los equipos de trabajo la posibilidad de utilizar de forma segura las mejores herramientas de Internet sin problemas de gestión o rendimiento. Nos complace anunciar Cloudflare One para IA, un nuevo conjunto de funciones que ayudan a tu equipo a desarrollar con los últimos servicios de IA sin dejar de mantener una postura de seguridad Zero Trust.</p>
	<h3 id="modelos-de-lenguaje-de-gran-tama%C3%B1o-el-nuevo-desaf%C3%ADo-para-la-seguridad">Modelos de lenguaje de gran tamaño, el nuevo desafío para la seguridad</h3>
	<p>Un modelo de lenguaje de gran tamaño (LLM), como GPT de OpenAI o Bard de Google, consiste en una red neuronal entrenada con un conjunto de datos para predecir y generar texto a partir de una pregunta. Los usuarios pueden hacer preguntas, solicitar opiniones y apoyarse en el servicio para crear resultados, desde poesía hasta <a href="https://blog.samrhea.com/posts/2022/five-minute-ai-site">aplicaciones de Cloudflare Workers</a>.</p>
	<p>Las herramientas también tienen un asombroso parecido con un ser humano real. Al igual que ocurre en algunas conversaciones personales de la vida real, compartir en exceso se puede convertir en un <a href="https://mashable.com/article/samsung-chatgpt-leak-details">grave problema</a> con estos servicios de IA. Este riesgo se multiplica debido a los tipos de casos de uso en los que se desarrollan los modelos LLM. Estas herramientas pueden ayudar a los desarrolladores a resolver problemas de codificación difíciles o ayudar a los profesionales de la información a crear informes resumidos a partir de notas desordenadas. Aunque son útiles, cada solicitud se convierte en un dato que sale del control de tu organización.</p>
	<p>En algunos casos, la respuesta a herramientas como ChatGPT ha sido intentar prohibir el servicio directamente, ya sea a nivel corporativo o en <a href="https://www.reuters.com/technology/germany-principle-could-block-chat-gpt-if-needed-data-protection-chief-2023-04-03">todo un país</a>. No creemos que debas hacerlo. El objetivo de Cloudflare One es permitirte utilizar con seguridad las herramientas que necesitas, independientemente de donde se alojen, sin afectar al rendimiento. Estas funciones te resultarán familiares si ya utilizas los productos Zero Trust de Cloudflare One, pero nos complace explicarte casos en los que puedes utilizar las herramientas disponibles ahora mismo para que tu equipo pueda aprovechar las últimas funciones de LLM.</p>
	<h3 id="mide-el-uso">Mide el uso</h3>
	<p>Las aplicaciones SaaS facilitan que cualquier usuario se registre y empiece a realizar pruebas. Esa ventaja también convierte a estas herramientas en un inconveniente para los presupuestos informáticos y las políticas de seguridad. Los equipos se refieren a este problema como "<a href="https://blog.cloudflare.com/es-es/introducing-shadow-it-discovery-es-es">Shadow IT</a>", la implementación de aplicaciones y servicios fuera de los canales autorizados en una organización.</p>
	<p>En lo que respecta a los presupuestos, hemos oído hablar de clientes pioneros que saben que los miembros de su equipo están empezando a experimentar con el LLM, pero no están seguros de cómo abordar la decisión en cuanto a las licencias comerciales se refiere. ¿Qué servicios y funciones necesitan sus usuarios y cuántas licencias deben adquirir?</p>
	<p>En cuanto a la seguridad, las herramientas de IA pueden ser revolucionarias para hacer el trabajo, pero terribles para las políticas de control de datos. Los miembros de los equipos tratan estas herramientas como cajas de resonancia para problemas acuciantes. Los servicios invitan a los usuarios a proponer preguntas o problemas. A veces, el contexto dentro de esas solicitudes puede contener información confidencial que nunca debería salir de una organización. Incluso si los equipos seleccionan y aprueban un único proveedor, los miembros de tu organización podrían preferir otra herramienta de IA y utilizarla en su flujo de trabajo.</p>
	<p>Los clientes de Cloudflare One de cualquier plan <a href="https://developers.cloudflare.com/cloudflare-one/analytics/access">ya pueden revisar</a> el uso de las herramientas IA. Tu departamento de informática puede implementar Cloudflare Gateway y observar pasivamente cuántos usuarios seleccionan los servicios, y qué servicios son, como forma de empezar a analizar los planes de licencias para empresas.</p>
	<figure class="kg-card kg-image-card kg-width-wide"><img src="https://blog.cloudflare.com/content/images/2023/05/image6-5.png" class="kg-image" alt="" loading="lazy" width="1879" height="682"></figure>
	<p>Los administradores también pueden bloquear el uso de estos servicios con un solo clic, pero ese no es nuestro objetivo hoy. Puede que quieras utilizar esta función si seleccionas ChatGPT como modelo autorizado y quieres asegurarte de que los miembros del equipo no utilizan otras alternativas, pero esperamos que no bloquees todos estos servicios directamente. La prioridad de Cloudflare es ofrecerte la posibilidad de utilizar estas herramientas de forma segura.</p>
	<h3 id="controla-el-acceso-a-las-api">Controla el acceso a las API</h3>
	<p>Cuando nuestros equipos empezaron a experimentar con el servicio ChatGPT de OpenAI, nos sorprendió lo que ya sabía sobre Cloudflare. Pedimos a ChatGPT que creara aplicaciones con <a href="https://workers.cloudflare.com">Cloudflare Workers</a> o que nos guiara sobre cómo configurar una política de <a href="https://www.cloudflare.com/products/zero-trust/access">Cloudflare Access</a> y, en la mayoría de los casos, los resultados fueron exactos y útiles.</p>
	<p>En algunos casos, los resultados no acertaron. Las herramientas de IA utilizaban información obsoleta o hacíamos preguntas sobre funciones que se habían lanzado recientemente. Afortunadamente, estos servicios de IA pueden aprender y nosotros podemos ayudar. Podemos entrenar estos modelos con entradas específicas y <a href="https://openai.com/blog/chatgpt-plugins">conectar complementos</a> para ofrecer a nuestros clientes mejores experiencias guiadas por la IA cuando utilicen los servicios de Cloudflare.</p>
	<p>Hemos oído a clientes que quieren hacer lo mismo y, como nosotros, necesitan compartir de forma segura los datos de entrenamiento y conceder acceso a los complementos para un servicio de IA. El conjunto de medidas de seguridad de Cloudflare One va más allá de los usuarios humanos y puede ofrecer a los equipos la capacidad de compartir de forma segura el acceso Zero Trust a datos confidenciales a través de las API.</p>
	<p>En primer lugar, los equipos pueden crear <a href="https://developers.cloudflare.com/cloudflare-one/identity/service-tokens">tokens de servicio</a> que los servicios externos deben presentar para acceder a los datos disponibles a través de Cloudflare One. Los administradores pueden proporcionar estos tokens a los sistemas que realicen solicitudes API y registrar cada solicitud. Cuando sea necesario, los equipos pueden revocar estos tokens con un solo clic.</p>
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2023/05/download-7.png" class="kg-image" alt="" loading="lazy" width="1600" height="1317"></figure>
	<p>Después de crear y emitir tokens de servicio, los administradores pueden crear políticas para permitir el acceso de servicios específicos a sus datos de entrenamiento. Estas políticas verificarán el token de servicio y se pueden ampliar para verificar el país, la dirección IP o un certificado mTLS. También se pueden crear políticas para exigir a los usuarios humanos que se autentiquen con un proveedor de identidad y completen una solicitud de autenticación multifactor (MFA) antes de acceder a datos o servicios de entrenamiento confidenciales.</p>
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2023/05/download--1--4.png" class="kg-image" alt="" loading="lazy" width="1600" height="1100"></figure>
	<p>Cuando los equipos estén preparados para permitir que un servicio de IA se conecte a su infraestructura, pueden hacerlo sin crear agujeros en sus firewalls gracias al uso de Cloudflare Tunnel. <a href="https://developers.cloudflare.com/cloudflare-one/connections/connect-apps">Cloudflare Tunnel</a> creará una conexión cifrada, y solo de salida, a la red de Cloudflare, donde cada solicitud se cotejará con las reglas de acceso configuradas para uno o más servicios protegidos por Cloudflare One.</p>
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2023/05/download--2--3.png" class="kg-image" alt="" loading="lazy" width="1600" height="1100"></figure>
	<p>El control de acceso Zero Trust de Cloudflare te ofrece la posibilidad de imponer la autenticación en todas y cada una de las solicitudes realizadas a los datos que tu organización decida proporcionar a estas herramientas. Sin embargo, los miembros de tu equipo podrían seguir compartiendo información por su cuenta.</p>
	<h3 id="restringe-la-carga-de-datos">Restringe la carga de datos</h3>
	<p>Los administradores pueden seleccionar un servicio de IA, bloquear las alternativas de Shadow IT y controlar cuidadosamente el acceso a su material de entrenamiento, pero en estos experimentos de IA siguen interviniendo seres humanos. Cualquiera de nosotros puede provocar accidentalmente un incidente de seguridad si compartimos información en exceso durante el proceso de uso de un servicio de IA, incluso un servicio autorizado.</p>
	<p>Esperamos que los campos de juego de la IA sigan evolucionando para ofrecer más capacidades de gestión de datos, pero no creemos que debas esperar para empezar a adoptar estos servicios como parte de tu flujo de trabajo. El servicio de <a href="https://developers.cloudflare.com/cloudflare-one/policies/data-loss-prevention/dlp-policies">prevención de pérdida de datos</a> (DLP) de Cloudflare puede ofrecer protección para evitar compartir en exceso antes de que se convierta en un incidente para tu equipo de seguridad.</p>
	<p>En primer lugar, dinos qué datos te preocupan. Ofrecemos opciones sencillas y preconfiguradas que te dan la posibilidad de comprobar datos que parecen números de la seguridad social o de tarjetas de crédito. Nuestra herramienta también puede buscar patrones basados en expresiones regulares configuradas por tu equipo.</p>
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2023/05/download--3--3.png" class="kg-image" alt="" loading="lazy" width="1600" height="1100"></figure>
	<p>Una vez que hayas definido los datos que nunca deben salir de tu organización, puedes crear reglas granulares sobre cómo pueden y no pueden compartirse con los servicios de IA. Tal vez algunos usuarios estén autorizados a experimentar con proyectos que contienen datos confidenciales, en cuyo caso puedes crear una regla que solo permita a un grupo de Active Directory u Okta subir ese tipo de información, y bloquear al resto.</p>
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2023/05/download--4--3.png" class="kg-image" alt="" loading="lazy" width="1600" height="1100"></figure>
	<h3 id="controla-el-uso-sin-un-proxy">Controla el uso sin un proxy</h3>
	<p>Las herramientas de la publicación del blog de hoy se centran en las funciones que se aplican a los datos en movimiento. También queremos asegurarnos de que las configuraciones erróneas en las aplicaciones no vulneren la seguridad. Por ejemplo, la nueva función de complemento de ChatGPT incorpora el conocimiento y los flujos de trabajo de servicios externos en el flujo de interacción de la IA. Sin embargo, esta novedad también puede otorgar más acceso del deseado a los servicios de los complementos.</p>
	<p>El <a href="https://www.cloudflare.com/es-es/products/zero-trust/casb">agente de seguridad de acceso a la nube</a> (CASB) de Cloudflare analiza tus aplicaciones SaaS en busca de posibles problemas que puedan surgir cuando los usuarios realizan cambios. Ya sea alertándote de archivos que alguien acaba de hacer públicos accidentalmente en Internet o comprobando que tus <a href="https://developers.cloudflare.com/cloudflare-one/applications/scan-apps/casb-integrations/github/#security-findings">repositorios de GitHub tienen los controles de suscripción adecuados</a>, el CASB de Cloudflare elimina el trabajo manual necesario para comprobar todos y cada uno de los ajustes en busca de posibles problemas en tus aplicaciones SaaS.</p>
	<p>Estamos trabajando en nuevas integraciones con servicios de IA populares, disponibles próximamente, para comprobar si hay configuraciones erróneas. Como la mayoría de los usuarios de estos servicios, seguimos aprendiendo sobre dónde se pueden producir accidentes potenciales, y estamos encantados de proporcionar a los administradores que utilizan nuestro CASB nuestra primera oleada de controles para los servicios de IA.</p>
	<h3 id="%C2%BFy-despu%C3%A9s">¿Y después?</h3>
	<p>La utilidad de estas herramientas no hará sino acelerarse. La capacidad de los servicios de IA para entrenar y generar resultados seguirá facilitando a los desarrolladores, sin importar su experiencia, la creación de su próxima aplicación asombrosa.</p>
	<p>Compartimos un objetivo similar. Nuestra <a href="https://workers.cloudflare.com">plataforma Workers</a>, que incluye los productos de Cloudflare cuyo objetivo es ayudar a los usuarios a crear aplicaciones y servicios, elimina la preocupación del lugar en el que implementar tu aplicación o cómo escalar tus servicios. Cloudflare resuelve estas dificultades para que los usuarios puedan centrarse en desarrollar. Junto con los servicios de IA, esperamos ver a miles de nuevos desarrolladores lanzar la próxima oleada de productos creados en Cloudflare e inspirados en el entrenamiento y la generación de IA.</p>
	<p>Ya hemos visto el desarrollo de docenas de proyectos en Cloudflare Workers utilizando la orientación de herramientas como ChatGPT. Tenemos previsto lanzar nuevas integraciones con estos modelos para que este objetivo sea aún más fácil, aportando mejor orientación específica de Cloudflare a la experiencia de chat.<br></p>
	<p>También sabemos que el riesgo de seguridad de estas herramientas irá en aumento. Seguiremos implementando funciones en Cloudflare One con el objetivo de ir un paso por delante de los riesgos a medida que evolucionan con estos servicios. ¿Todo listo para empezar? Regístrate aquí para empezar a utilizar Cloudflare One, gratuito para equipos de hasta 50 usuarios.</p>
</div>