{
	"author": {
		"name": "Jesse Kipp",
		"url": "http://blog.cloudflare.com/author/jesse/",
		"sameAs": []
	},
	"headline": "Streaming and longer context lengths for LLMs on Workers AI",
	"url": "http://blog.cloudflare.com/workers-ai-streaming/",
	"datePublished": "2023-11-14T14:00:33.000Z",
	"dateModified": "2023-11-29T00:21:20.000Z",
	"image": "http://blog.cloudflare.com/content/images/2023/10/pasted-image-0--3--3.png",
	"keywords": "Workers AI, Cloudflare Workers, Developer Platform, JavaScript, Serverless",
	"description": "Workers AI now supports streaming text responses for the LLM models in our catalog, including Llama-2, using server-sent events"
}