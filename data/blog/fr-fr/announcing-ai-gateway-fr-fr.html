<div class="mb2 gray5">7 min read</div>
<div class="post-content lh-copy gray1">
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2023/09/image4-10.png" class="kg-image" alt="Announcing AI Gateway: making AI applications more observable, reliable, and scalable" loading="lazy" width="1801" height="1014"></figure>
	<p>Aujourd'hui, nous sommes ravis d'annoncer notre version bêta d' <strong>AI Gateway</strong> – le portail pour rendre vos applications d'IA plus observables, fiables et évolutives.</p>
	<p>AI Gateway s'interpose entre votre application et les API d'IA auxquelles votre application adresse des requêtes (comme OpenAI) - afin que nous puissions mettre en cache les réponses, limiter et réessayer les requêtes, et fournir des analyses pour vous aider à surveiller et à suivre l'utilisation. AI Gateway gère tous les aspects nécessaires à la quasi-totalité des applications d'IA, vous permettant ainsi d'économiser le temps consacré au développement afin de vous concentrer sur ce que vous créez.</p>
	<h3 id="connecter-votre-application-%C3%A0-ai-gateway">Connecter votre application à AI Gateway</h3>
	<p>Il suffit d'une ligne de code pour que les développeurs commencent à utiliser AI Gateway de Cloudflare. Tout ce que vous avez à faire est de remplacer l'URL dans vos appels API par votre point de terminaison AI Gateway unique. Par exemple, avec OpenAI, vous devez définir votre baseURL comme <code>"https://gateway.ai.cloudflare.com/v1/ACCOUNT_TAG/GATEWAY/openai"</code> au lieu de <code>"https://api.openai.com/v1"</code> – et c'est tout. Vous pouvez conserver vos jetons dans votre environnement de code, et nous enregistrerons la demande à travers AI Gateway avant de la laisser passer à l'API finale avec votre jeton.</p><!--kg-card-begin: markdown-->
	<pre><code class="language-JavaScript">// configuring AI gateway with the dedicated OpenAI endpoint

const openai = new OpenAI({
&nbsp; apiKey: env.OPENAI_API_KEY,
&nbsp; baseURL: "https://gateway.ai.cloudflare.com/v1/ACCOUNT_TAG/GATEWAY/openai",
});
</code></pre>
	<!--kg-card-end: markdown-->
	<p>Nous prenons actuellement en charge des fournisseurs de modèles tels que OpenAI, Hugging Face et Replicate, et nous prévoyons d'en ajouter d'autres à l'avenir. Nous prenons en charge les différents points de terminaison des fournisseurs ainsi que la diffusion des réponses, de sorte que tout devrait fonctionner dès que vous aurez configuré la passerelle. Le point de terminaison dédié à ces fournisseurs vous permet de connecter vos applications à AI Gateway en changeant une ligne de code, sans toucher à la structure originale de votre contenu utile.</p>
	<p>Nous disposons également d'un point de terminaison universel que vous pouvez utiliser si vous souhaitez bénéficier d'une plus grande souplesse dans vos demandes. Avec le point de terminaison universel, vous avez la possibilité de définir des modèles de repli et de gérer les tentatives de requêtes. Par exemple, supposons qu'une demande ait été faite à OpenAI GPT-3, mais que l'API soit en panne - avec le point de terminaison universel, vous pouvez définir Hugging Face GPT-2 comme modèle de repli et la passerelle peut automatiquement renvoyer cette demande à Hugging Face. Ceci est très utile pour améliorer la résilience de votre application dans les cas où vous remarquez des erreurs inhabituelles, où vous obtenez un taux limité, ou si une facture devient coûteuse, et que vous voulez diversifier vers d'autres modèles. Avec le point de terminaison universel, il vous suffit de modifier votre contenu utile pour spécifier le fournisseur et le point de terminaison, afin que nous puissions acheminer correctement les requêtes pour vous. Consultez l'exemple de requête ci-dessous et <a href="https://developers.cloudflare.com/ai-gateway" target="_blank">la documentation</a> pour plus de détails sur le schéma du point de terminaison universel.</p><!--kg-card-begin: markdown-->
	<pre><code class="language-bash"># Using the Universal Endpoint to first try OpenAI, then Hugging Face

curl https://gateway.ai.cloudflare.com/v1/ACCOUNT_TAG/GATEWAY &nbsp;-X POST \
&nbsp; --header 'Content-Type: application/json' \
&nbsp; --data '[
&nbsp; {
&nbsp; &nbsp; "provider": "openai",
&nbsp; &nbsp; "endpoint": "chat/completions",
&nbsp; &nbsp; "headers": { 
&nbsp; &nbsp; &nbsp; "Authorization": "Bearer $OPENAI_TOKEN",
&nbsp; &nbsp; &nbsp; "Content-Type": "application/json"
&nbsp; &nbsp; },
&nbsp; &nbsp; "query": {
&nbsp; &nbsp; &nbsp; "model": "gpt-3.5-turbo",
&nbsp; &nbsp; &nbsp; "stream": true,
&nbsp; &nbsp; &nbsp; "messages": [
&nbsp; &nbsp; &nbsp; &nbsp; {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "role": "user",
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; "content": "What is Cloudflare?"
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; ]
&nbsp; &nbsp; }
&nbsp; },
&nbsp; {
&nbsp; &nbsp; "provider": "huggingface",
&nbsp; &nbsp; "endpoint": "gpt2",
&nbsp; &nbsp; "headers": { 
&nbsp; &nbsp; &nbsp; "Authorization": "Bearer $HF_TOKEN",
&nbsp; &nbsp; &nbsp; "Content-Type": "application/json"
&nbsp; &nbsp; },
&nbsp; &nbsp; "query": {
&nbsp; &nbsp; &nbsp; "inputs": "What is Cloudflare?"
&nbsp; &nbsp; }
&nbsp; },
]'
</code></pre>
	<!--kg-card-end: markdown-->
	<h3 id="obtenir-de-la-visibilit%C3%A9-sur-lutilisation-de-votre-application">Obtenir de la visibilité sur l'utilisation de votre application</h3>
	<p>Maintenant que votre application est connectée à Cloudflare, nous pouvons vous aider à recueillir des données analytiques et vous donner un aperçu et un contrôle du trafic qui passe par vos applications. Quel que soit le modèle ou l'infrastructure que vous utilisez dans le backend, nous pouvons vous aider à enregistrer les requêtes et à analyser des données telles que le nombre de requêtes, le nombre d'utilisateurs, le coût de fonctionnement de l'application, la durée des requêtes, etc. Bien qu'il s'agisse là d'analyses de base que les fournisseurs de modèles devraient présenter, il est étonnamment difficile d'obtenir une visibilité sur ces mesures avec les fournisseurs de modèles habituels. AI Gateway va encore plus loin et vous permet d'agréger les analyses de plusieurs fournisseurs.</p>
	<figure class="kg-card kg-image-card kg-width-wide"><img src="https://blog.cloudflare.com/content/images/2023/09/image3-24.png" class="kg-image" alt="" loading="lazy" width="1999" height="1418"></figure>
	<h3 id="contr%C3%B4ler-l%C3%A9volution-de-votre-application">Contrôler l'évolution de votre application</h3>
	<p>L'un des points douloureux que nous entendons souvent est le coût de la création et de l'exécution des applications d'IA. Chaque appel à l'API peut être imprévisible et les coûts peuvent s'accumuler rapidement, empêchant les développeurs de faire évoluer leurs applications à leur plein potentiel. À la vitesse à laquelle l'industrie évolue, vous ne voulez pas être limité par votre échelle et rester à la traîne - et c'est là que la mise en cache et le controle du volume de requêtes peuvent vous aider. Nous permettons aux développeurs de mettre en cache leurs appels d'API afin que les nouvelles requêtes puissent être servies à partir de notre cache plutôt que de l'API d'origine, ce qui est moins coûteux et plus rapide. Le <a href="https://www.cloudflare.com/learning/bots/what-is-rate-limiting" target="_blank">Controle du volume de requêtes</a> peut également contribuer à la maîtrise des coûts en limitant le nombre de demandes et en empêchant toute activité excessive ou suspecte. Les développeurs ont toute latitude pour définir les règles de mise en cache et de contrôle du volume (de requêtes), de sorte que les applications peuvent évoluer au rythme que vous souhaitez.</p>
	<figure class="kg-card kg-image-card kg-width-wide"><img src="https://blog.cloudflare.com/content/images/2023/09/image1-20.png" class="kg-image" alt="" loading="lazy" width="1999" height="1308"></figure>
	<h3 id="la-plateforme-workers-ai">La plateforme Workers AI</h3>
	<p>AI Gateway s'associe parfaitement à nos nouveaux produits <a href="https://blog.cloudflare.com/workers-ai">Workers AI</a> et <a href="https://blog.cloudflare.com/vectorize-vector-database-open-beta">Vectorize</a>, afin que vous puissiez créer des applications d'IA full-stack au sein de l'écosystème Workers. Qu'il s'agisse de déployer des applications avec Workers, d'exécuter l'inférence de modèles à la périphérie avec Workers AI, de stocker des embeddings vectoriels sur Vectorize ou d'obtenir une visibilité sur vos applications avec AI Gateway, la plateforme Workers est votre guichet unique pour donner vie à vos applications d'IA. Pour savoir comment utiliser AI Gateway avec Workers AI ou les différents fournisseurs, consultez <a href="https://developers.cloudflare.com/ai-gateway" target="_blank">notre documentation</a>.</p>
	<h3 id="prochaine-%C3%A9tape-le-cas-dutilisation-en-entreprise">Prochaine étape : le cas d'utilisation en entreprise</h3>
	<p>Nous livrons la version 1 d'AI Gateway avec quelques fonctionnalités de base, mais nous avons l'intention de développer le produit pour couvrir des cas d'utilisation plus avancés - alertes d'utilisation, protection contre le jailbreak, routage dynamique de modèles avec tests A/B, et cache rules avancées. Mais ce qui nous intéresse vraiment, ce sont les autres manières d'appliquer AI Gateway...</p>
	<p>À l'avenir, nous voulons développer AI Gateway pour en faire un produit qui aide les organisations à surveiller et à observer comment leurs utilisateurs ou leurs employés utilisent l'IA. De cette façon, vous pouvez appuyer sur un interrupteur et faire en sorte que toutes les requêtes au sein de votre réseau vers des fournisseurs (comme OpenAI) passent d'abord par Cloudflare - afin que vous puissiez enregistrer les requêtes des utilisateurs, appliquer des politiques d'accès, activer des stratégies de controle du volume de requêtes et de <a href="https://www.cloudflare.com/learning/access-management/what-is-dlp" target="_blank">prévention de perte de données (DLP)</a>. Un exemple puissant : si un employé colle accidentellement une clé API à ChatGPT, AI Gateway peut être configuré pour voir la requête sortante et expurger la clé API ou bloquer complètement la requête, l'empêchant ainsi d'atteindre OpenAI ou tout autre fournisseur final. Nous pouvons également enregistrer et vous alerter sur les requêtes suspectes, afin que les organisations puissent enquêter de manière proactive et contrôler certains types d'activité. AI Gateway devient alors un outil vraiment puissant pour les organisations qui pourraient être emballées par l'efficacité que l'IA débloque, mais qui hésitent à faire confiance à l'IA lorsque la confidentialité des données et l'erreur de l'utilisateur sont des menaces vraiment critiques. Nous espérons qu'AI Gateway pourra atténuer ces inquiétudes et faciliter l'adoption des outils d'IA par les organisations.</p>
	<p>Que vous soyez un développeur d'applications ou une entreprise intéressée par la façon dont vos employés utilisent l'IA, nous espérons que AI Gateway vous aidera à démystifier ce qui se passe à l'intérieur de vos applications - car une fois que vous aurez compris comment vos utilisateurs se servent de l'IA, vous pourrez prendre des décisions sur la façon dont vous voulez qu'ils l'utilisent. Certaines de ces fonctionnalités sont encore en développement, mais nous espérons qu'elles témoignent de la puissance de AI Gateway et de notre vision de l'avenir.</p>
	<p>Chez Cloudflare, nous ne jurons que par l'innovation (comme vous pouvez le constater par les annonces de notre Semaine anniversaire !) et le rythme de l'innovation dans le domaine de l'IA est absolument stupéfiant. Nous sommes ravis de pouvoir non seulement aider les gens à créer et à utiliser des applications, mais aussi d'<em>accélérer</em> l'adoption et le développement de l'IA grâce à un meilleur contrôle et à une plus grande visibilité. Nous sommes impatients de découvrir ce que vous allez créer - consultez le tableau de bord de Cloudflare pour <a href="https://dash.cloudflare.com/?to=%2F%3Aaccount%2Fai%2Fai-gateway%2Fgeneral%29" target="_blank">essayer AI Gateway</a> et dites-nous ce que vous en pensez !</p>
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2023/09/image2-17.png" class="kg-image" alt="" loading="lazy" width="1800" height="588"></figure>
</div>