<div class="post-content lh-copy gray1">
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2023/05/image4-6.png" class="kg-image" alt="Introducing Constellation, bringing AI to the Cloudflare stack" loading="lazy" width="1200" height="675"></figure>
	<p>L'écosystème de Cloudflare Workers comprend désormais des produits et des fonctionnalités telles que le traitement, l'hébergement, le stockage, les bases de données, le streaming, la connectivité réseau, la sécurité et <a href="https://developers.cloudflare.com/?ref=blog.cloudflare.com" target="_blank">bien d'autres</a>. Au fil du temps, nous avons essayé d'inspirer les autres à délaisser les architectures logicielles traditionnelles, <a href="https://blog.cloudflare.com/welcome-to-wildebeest-the-fediverse-on-cloudflare/">en démontrant</a> et <a href="https://blog.cloudflare.com/fr-fr/technology-behind-radar2-fr-fr/">en documentant</a> de quelle manière il est possible de construire des applications complexes, capables d'évoluer à l'échelle mondiale, avec notre pile.</p>
	<p>Aujourd'hui, nous sommes heureux d'accueillir Constellation au sein de la pile Cloudflare. Ce service permet aux développeurs d'exécuter rapidement des modèles d'apprentissage automatique préalablement entraînés ainsi que des tâches d'inférence sur le réseau de Cloudflare.</p>
	<h2 id="une-composante-de-plus-au-sein-de-notre-supercloud">Une composante de plus au sein de notre Supercloud</h2>
	<p>Dernièrement, l'<a href="https://en.wikipedia.org/wiki/Machine_learning?ref=blog.cloudflare.com" target="_blank">apprentissage automatique</a> et l'intelligence artificielle se sont imposés comme des sujets d'actualité ; la réalité, toutefois, est que nous utilisons ces technologies dans notre quotidien depuis des années, même si nous n'en avons pas conscience. Nos téléphones portables, nos ordinateurs, nos voitures et nos assistants domestiques, pour ne citer que quelques exemples, disposent tous de l'IA. Elle est omniprésente.</p>
	<p>Cependant, elle n'est pas encore aisément accessible aux développeurs. Ils doivent souvent comprendre les principes mathématiques sur lesquelles elle repose ; les logiciels et les outils sont dispersés et complexes, et les équipements ou les services cloud indispensables à l'exécution des frameworks et des données sont coûteux.</p>
	<p><strong>Aujourd'hui, nous introduisons, dans notre pile, une nouvelle fonctionnalité, qui permettra à tous les utilisateurs d'exécuter des modèles d'apprentissage automatique et d'exécuter des inférences sur Cloudflare Workers.</strong></p>
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2023/05/image2-8.png" class="kg-image" alt="" loading="lazy" width="1784" height="510"></figure>
	<h2 id="d%C3%A9couvrez-constellation">Découvrez Constellation</h2>
	<p>Constellation vous permet d'exécuter rapidement des tâches d'inférence à faible latence sur des modèles d'apprentissage automatique préalablement entraînés avec des scripts Cloudflare Workers.</p>
	<p>Voici quelques exemples d'applications que vous pouvez déployer avec Constellation :</p>
	<ul>
		<li>Classification d'images ou d'audio ou détection d'objets</li>
		<li>Détection d'anomalies dans des données</li>
		<li>Traduction, résumé ou analyse de similarité de textes</li>
		<li>Traitement du langage naturel</li>
		<li>Analyse des sentiments</li>
		<li>Reconnaissance vocale ou synthèse vocale</li>
		<li>Réponses à des questions</li>
	</ul>
	<p>Les développeurs peuvent transférer n'importe quel modèle pris en charge vers Constellation. Ils peuvent entraîner un modèle indépendamment, ou transférer des modèles préalablement entraînés depuis des portails d'apprentissage automatique tels que <a href="https://huggingface.co/models?library=onnx&amp;sort=downloads&amp;ref=blog.cloudflare.com" target="_blank">HuggingFace</a> ou <a href="https://github.com/onnx/models?ref=blog.cloudflare.com" target="_blank">ONNX Zoo</a>.</p>
	<p>Cependant, tous les utilisateurs ne souhaitent pas former des modèles ou parcourir l'Internet à la recherche de modèles qu'ils n'ont pas encore testés ; c'est pourquoi Cloudflare conservera également un catalogue de modèles vérifiés et prêts à l'emploi.</p>
	<p>Nous avons conçu Constellation dans l'optique de prioriser l'expérience des développeurs et la simplicité d'utilisation des API. Voici un exemple pour vous aider à vous lancer.</p>
	<h2 id="application-de-classification-dimages">Application de classification d'images</h2>
	<p>Dans cet exemple, nous allons créer une application de classification d'images reposant sur l'API d'inférence de Constellation et le modèle <a href="https://github.com/onnx/models/blob/main/vision/classification/squeezenet/README.md?ref=blog.cloudflare.com" target="_blank">SqueezeNet</a>, un réseau neuronal convolutif (CNN, « Convolutional Neural Network »), qui a été préalablement entraîné avec plus d'un million d'images issues de la base de données open source <a href="https://www.image-net.org/?ref=blog.cloudflare.com" target="_blank">ImageNet</a>, et qui peut assurer la classification d'images dans 1 000 catégories maximum.</p>
	<p>Comparé à <a href="https://en.wikipedia.org/wiki/AlexNet?ref=blog.cloudflare.com" target="_blank">AlexNet</a>, l'un des réseaux CNN originaux et un modèle de référence en matière de classification d'images, SqueezeNet est beaucoup plus rapide (environ 3x) et beaucoup moins volumineux (environ 500x), tout en offrant des niveaux de précision similaires. Son faible encombrement en fait un outil idéal pour les appareils portables dotés de ressources limitées ou les équipements sur mesure.</p>
	<p>Pour commencer, créons un nouveau projet Constellation avec l'environnement d'exécution ONNX. Wrangler propose désormais une fonctionnalité intégrée pour Constellation avec le mot-clé « <code>constellation</code> ».</p><!--kg-card-begin: markdown-->
	<pre><code>$ npx wrangler constellation project create "image-classifier" ONNX
</code></pre>
	<!--kg-card-end: markdown-->
	<p>Créons maintenant le fichier de configuration <code>wrangler.toml</code> avec la liaison de projet :</p><!--kg-card-begin: markdown-->
	<pre><code class="language-yaml"># Top-level configuration
name = "image-classifier-worker"
main = "src/index.ts"
compatibility_date = "2022-07-12"

constellation = [
    {
      binding = 'CLASSIFIER',
      project_id = '2193053a-af0a-40a6-b757-00fa73908ef6'
    },
]
</code></pre>
	<!--kg-card-end: markdown-->
	<p>Installation de la bibliothèque d'API du client Constellation :</p><!--kg-card-begin: markdown-->
	<pre><code>$ npm install @cloudflare/constellation --save-dev
</code></pre>
	<!--kg-card-end: markdown-->
	<p>Transférez le modèle ONNX SqueezeNet 1.1 préalablement entraîné vers le projet.</p><!--kg-card-begin: markdown-->
	<pre><code>$ wget https://github.com/microsoft/onnxjs-demo/raw/master/docs/squeezenet1_1.onnx
$ npx wrangler constellation model upload "image-classifier" "squeezenet11" squeezenet1_1.onnx
</code></pre>
	<!--kg-card-end: markdown-->
	<p>Comme nous l'avons dit plus haut, SqueezeNet assure la classification d'images dans 1 000 classes d'objets maximum. Concrètement, ces classes se présentent sous la forme d'une liste d'ensembles de synonymes, ou « synset ». Un <a href="http://wordnet-rdf.princeton.edu/pwn30/01440764-n?ref=blog.cloudflare.com" target="_blank">synset</a> comporte un identifiant et un intitulé ; il est issu de <a href="https://wordnet.princeton.edu/?ref=blog.cloudflare.com" target="_blank">WordNet</a>, la base de données <a href="https://wordnet.princeton.edu/documentation/?ref=blog.cloudflare.com" target="_blank">terminologique</a> de l'Université Princeton, qui est également utilisée pour l'identification du contenu de la base de données d'images <a href="https://www.image-net.org/about.php?ref=blog.cloudflare.com" target="_blank">ImageNet</a>.</p>
	<p>Pour traduire les résultats de SqueezeNet sous forme de classes d'images en langage humain intelligible, nous avons besoin d'un fichier qui associe les identifiants de synset (c'est-à-dire ce que nous obtenons du modèle) et les identifiants correspondants.</p><!--kg-card-begin: markdown-->
	<pre><code>$ mkdir src; cd src
$ wget https://raw.githubusercontent.com/microsoft/onnxjs-demo/master/src/data/imagenet.ts
</code></pre>
	<!--kg-card-end: markdown-->
	<p>Enfin, codons et déployons notre script de classification d'images :</p><!--kg-card-begin: markdown-->
	<pre><code class="language-javascript">import { imagenetClasses } from './imagenet';
import { Tensor, run } from '@cloudflare/constellation';

export interface Env {
    CLASSIFIER: any,
}

export default {
    async fetch(request: Request, env: Env, ctx: ExecutionContext) {
        const formData = await request.formData();
        const file = formData.get("file");
        const data = await file.arrayBuffer();
        const result = await processImage(env, data);
        return new Response(JSON.stringify(result));
    },
};

async function processImage(env: Env, data: ArrayBuffer) {
    const input = await decodeImage(data)

    const tensorInput = new Tensor("float32", [1, 3, 224, 224], input)

    const output = await run(env.CLASSIFIER, "MODEL-UUID", tensorInput);

    const probs = output.squeezenet0_flatten0_reshape0.value
    const softmaxResult = softmax(probs)
    const results = imagenetClasses(softmaxResult, 5);
    const topResult = results[0];
    return topResult
}
</code></pre>
	<!--kg-card-end: markdown-->
	<p>Ce script lit une image depuis la requête, la décode sous forme de tenseur multidimensionnel float32 (à l'heure actuelle, seules les images au format PNG sont décodées, mais nous pouvons en ajouter d'autres), la transmet au modèle SqueezeNet en cours d'exécution dans Constellation, obtient les résultats, les associe à la liste de classes d'ImageNet, puis renvoie les identifiants en langage intelligible humain correspondant à l'image.</p>
	<p>C'est plutôt simple, non ? Testons le script ensemble :</p><!--kg-card-begin: markdown-->
	<pre><code>$ curl https://ai.cloudflare.com/demos/image-classifier -F file=@images/mountain.png | jq .name

alp

$ curl https://ai.cloudflare.com/demos/image-classifier -F file=@images/car.png | jq .name

convertible

$ curl https://ai.cloudflare.com/demos/image-classifier -F file=@images/dog.png | jq .name

Ibizan hound
</code></pre>
	<!--kg-card-end: markdown-->
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2023/05/Screenshot-2023-05-15-at-12.55.21.png" class="kg-image" alt="" loading="lazy" width="1888" height="682"></figure>
	<p>Ici, vous pouvez observer les probabilités en action. Le modèle est assez sûr de la montagne alpine et du cabriolet, mais la probabilité du podenco d'Ibiza est plus faible. En effet, le chien représenté sur la photo est d'une race différente.</p>
	<p>Cette petite application démontre à quel point il est facile et rapide d'utiliser des modèles d'apprentissage automatique et Constellation lors de la création d'applications avec Workers. Vous pouvez consulter le code source complet <a href="https://developers.cloudflare.com/constellation/get-started/first-constellation-worker/?ref=blog.cloudflare.com" target="_blank">ici</a> et le déployer vous-même.</p>
	<h2 id="transformeurs">Transformeurs</h2>
	<p>Les <a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)?ref=blog.cloudflare.com" target="_blank">transformeurs</a> ont été inaugurés par Google ; il s'agit de modèles d'apprentissage profond conçus pour traiter des données séquentielles fournies en entrée. Ils sont communément utilisés dans des applications de traitement du langage naturel (NLP, « Natural Language Processing »), telles que les traductions, les résumés ou l'analyse de sentiments, ainsi que dans les tâches d'interprétation de données visuelles (CV, « Computer Vision »), telles que la classification d'images.</p>
	<p><a href="https://github.com/xenova/transformers.js?ref=blog.cloudflare.com" target="_blank">Transformers.js</a> est une démo fréquemment utilisée, qui charge des modèles de transformeurs depuis HuggingFace et les exécute dans votre navigateur à l'aide de l'environnement d'exécution ONNX compilé en <a href="https://developers.cloudflare.com/workers/platform/web-assembly/?ref=blog.cloudflare.com" target="_blank">WebAssembly</a>. Au lieu de WebAssembly, nous avons transféré cette démo afin d'utiliser les API de Constellation.</p>
	<p>Voici le lien vers notre version : <a href="https://transformers-js.pages.dev/?ref=blog.cloudflare.com" target="_blank">https://transformers-js.pages.dev/</a></p>
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2023/05/image3-5.png" class="kg-image" alt="" loading="lazy" width="1999" height="1195"></figure>
	<h2 id="interop%C3%A9rabilit%C3%A9-avec-workers">Interopérabilité avec Workers</h2>
	<p>L'autre aspect intéressant de Constellation est que, puisque le service s'exécute nativement dans Workers, vous pouvez l'orchestrer avec d'autres produits et API de notre pile. Vous pouvez utiliser KV, R2, D1, Queues – tous les services de votre choix, même les e-mails !</p>
	<p>Voici un exemple d'instance Workers permettant de <a href="https://developers.cloudflare.com/email-routing/email-workers/?ref=blog.cloudflare.com" target="_blank">recevoir</a> les e-mails adressés à votre domaine sur Cloudflare avec le service <a href="https://developers.cloudflare.com/email-routing/?ref=blog.cloudflare.com" target="_blank">Email Routing</a>, d'exécuter Constellation avec le modèle d'analyse de sentiment <a href="https://huggingface.co/Xenova/t5-small/tree/main/onnx?ref=blog.cloudflare.com" target="_blank">t5-small</a>, d'ajouter un en-tête avec le score résultant, puis de transférer l'e-mail à l'adresse de destination.</p><!--kg-card-begin: markdown-->
	<pre><code class="language-javascript">import { Tensor, run } from '@cloudflare/constellation';
import * as PostalMime from 'postal-mime';

export interface Env {
    SENTIMENT: any,
}

export default {
  async email(message, env, ctx) {
    const rawEmail = await streamToArrayBuffer(event.raw, event.rawSize);
    const parser = new PostalMime.default();
    const parsedEmail = await parser.parse(rawEmail);

    const input = tokenize(parsedEmail.text)
    const output = await run( env.SENTIMENT, "MODEL-UUID", input);


    var headers = new Headers();
    headers.set("X-Sentiment", idToLabel[output.label]);
    await message.forward("gooddestination@example.com", headers);
  }
}
</code></pre>
	<!--kg-card-end: markdown-->
	<p>Vous pouvez maintenant utiliser Gmail ou tout autre client de messagerie pour appliquer à vos messages une règle sur la base de l'en-tête « X-Sentiment ». Par exemple, vous pouvez souhaiter déplacer tous les messages contenant un langage colérique hors de votre boîte de réception, vers un autre dossier, dès leur réception.</p>
	<h2 id="commencez-%C3%A0-utiliser-constellation">Commencez à utiliser Constellation</h2>
	<p>Le lancement de Constellation en version bêta privée a lieu aujourd'hui. Pour vous inscrire sur la liste d'attente, accédez au tableau de bord, cliquez sur l'onglet Workers sous votre compte, puis cliquez sur le bouton « Request access » (Demander l'accès). L'équipe assurera l'intégration des comptes par lots ; vous recevrez un e-mail lorsque votre compte sera activé.</p>
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2023/05/image1-25.png" class="kg-image" alt="" loading="lazy" width="1999" height="1426"></figure>
	<p>En attendant, vous pouvez consulter la <a href="https://developers.cloudflare.com/constellation/?ref=blog.cloudflare.com" target="_blank">documentation pour développeurs de Constellation</a> afin d'en apprendre davantage sur son fonctionnement et ses API. Le service Constellation peut être utilisé depuis Wrangler, notre outil de ligne de commande permettant de configurer, développer et déployer des applications avec les produits pour développeurs de Cloudflare ; vous pouvez également le gérer directement depuis l'interface utilisateur du tableau de bord.</p>
	<p>Nous sommes impatients de découvrir comment vous avez l'intention d'utiliser l'apprentissage automatique et l'intelligence artificielle dans vos applications. Constellation bénéficiera de nouvelles améliorations, avec des limites plus élevées, la prise en charge d'un plus grand nombre d'environnements d'exécution et des modèles plus vastes ; toutefois, nous voulons connaître votre avis, et vos commentaires influenceront certainement nos décisions concernant la feuille de route du service.</p>
	<p>Une dernière chose – aujourd'hui, nous avons parlé de la façon dont vous pouvez écrire des instances Workers qui utilisent Constellation, mais voici une information concernant sa création : le service Constellation lui-même a été développé grâce à la puissance de WebAssembly, de Workers, de R2 et de nos API. Nous proposerons prochainement un article de blog sur son développement ; restez à l'écoute !</p>
	<p>Comme d'habitude, vous pouvez échanger avec nous sur le <a href="https://discord.cloudflare.com/?ref=blog.cloudflare.com" target="_blank">Discord Cloudflare Developers</a> (rejoignez le canal #constellation) ou le <a href="https://community.cloudflare.com/c/developers/constellation/97?ref=blog.cloudflare.com" target="_blank">forum de la communauté</a> ; notre équipe est à votre écoute.</p>
</div>