{
	"locale": "en-us",
	"post": {
		"id": "5d16453b41acde0011a9580f",
		"uuid": "b4ac7bf2-4fe9-4242-bf87-693501580da2",
		"title": "eBPF can't count?!",
		"slug": "ebpf-cant-count",
		"html": "<figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"http://blog.cloudflare.com/content/images/2019/04/Grant_mechanical_calculating_machine_1877-1.jpg\" class=\"kg-image\" alt loading=\"lazy\"><figcaption>Grant mechanical calculating machine, public domain <a href=\"https://en.wikipedia.org/wiki/File:Grant_mechanical_calculating_machine_1877.jpg\">image</a></figcaption></figure><p></p><!--kg-card-begin: markdown--><p>It is unlikely we can tell you anything new about the extended Berkeley Packet Filter, eBPF for short, if you've read all the great <a href=\"http://man7.org/linux/man-pages/man2/bpf.2.html\">man pages</a>, <a href=\"https://www.kernel.org/doc/Documentation/networking/filter.txt\">docs</a>, <a href=\"https://cilium.readthedocs.io/en/latest/bpf/\">guides</a>, and some of our <a href=\"https://blog.cloudflare.com/epbf_sockets_hop_distance/\">blogs</a> out there.</p>\n<p>But we can tell you a war story, and who doesn't like those? This one is about how eBPF lost its ability to count for a while<a href=\"#f1\"><sup>1</sup></a>.</p>\n<p>They say in our Austin, Texas office that all good stories start with &quot;y'all ain't gonna believe this… tale.&quot; This one though, starts with a <a href=\"https://lore.kernel.org/netdev/CAJPywTJqP34cK20iLM5YmUMz9KXQOdu1-+BZrGMAGgLuBWz7fg@mail.gmail.com/\">post</a> to Linux netdev mailing list from <a href=\"https://twitter.com/majek04\">Marek Majkowski</a> after what I heard was a long night:</p>\n<!--kg-card-end: markdown--><p></p><figure class=\"kg-card kg-image-card\"><img src=\"http://blog.cloudflare.com/content/images/2019/04/ebpf_bug_email_netdev.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p></p><!--kg-card-begin: markdown--><p>Marek's findings were quite shocking - if you subtract two 64-bit timestamps in eBPF, the result is garbage. But only when running as an unprivileged user. From root all works fine. Huh.</p>\n<p>If you've seen Marek's <a href=\"https://speakerdeck.com/majek04/linux-at-cloudflare\">presentation</a> from the Netdev 0x13 conference, you know that we are using BPF socket filters as one of the defenses against simple, volumetric DoS attacks. So potentially getting your packet count wrong could be a Bad Thing™, and affect legitimate traffic.</p>\n<p>Let's try to reproduce this bug with a simplified <a href=\"https://github.com/cloudflare/cloudflare-blog/blob/master/2019-04-ebpf-alu32/bpf/filter.c#L63\">eBPF socket filter</a> that subtracts two 64-bit unsigned integers passed to it from <a href=\"https://github.com/cloudflare/cloudflare-blog/blob/master/2019-04-ebpf-alu32/run_bpf.go#L93\">user-space</a> though a BPF map. The input for our BPF program comes from a <a href=\"https://github.com/cloudflare/cloudflare-blog/blob/master/2019-04-ebpf-alu32/bpf/filter.c#L44\">BPF array map</a>, so that the values we operate on are not known at build time. This allows for easy experimentation and prevents the compiler from optimizing out the operations.</p>\n<p>Starting small, eBPF, what is 2 - 1? View the code <a href=\"https://github.com/cloudflare/cloudflare-blog/blob/master/2019-04-ebpf-alu32/run_bpf.go#L93\">on our GitHub</a>.</p>\n<pre><code>$ ./run-bpf 2 1\narg0                    2 0x0000000000000002\narg1                    1 0x0000000000000001\ndiff                    1 0x0000000000000001\n</code></pre>\n<p>OK, eBPF, what is 2^32 - 1?</p>\n<pre><code>$ ./run-bpf $[2**32] 1\narg0           4294967296 0x0000000100000000\narg1                    1 0x0000000000000001\ndiff 18446744073709551615 0xffffffffffffffff\n</code></pre>\n<p>Wrong! But if we ask nicely with sudo:</p>\n<pre><code>$ sudo ./run-bpf $[2**32] 1\n[sudo] password for jkbs:\narg0           4294967296 0x0000000100000000\narg1                    1 0x0000000000000001\ndiff           4294967295 0x00000000ffffffff\n</code></pre>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id=\"whoismessingwithmyebpf\">Who is messing with my eBPF?</h3>\n<p>When computers stop subtracting, you know something big is up. We called for reinforcements.</p>\n<p>Our colleague Arthur Fabre <a href=\"https://lore.kernel.org/netdev/20190301113901.29448-1-afabre@cloudflare.com/\">quickly noticed</a> something is off when you examine the eBPF code loaded into the kernel. It turns out kernel doesn't actually run the eBPF it's supplied - it sometimes rewrites it first.</p>\n<p>Any sane programmer would expect 64-bit subtraction to be expressed as <a href=\"https://github.com/cloudflare/cloudflare-blog/blob/master/2019-04-ebpf-alu32/bpf/filter.s#L47\">a single eBPF instruction</a></p>\n<pre><code>$ llvm-objdump -S -no-show-raw-insn -section=socket1 bpf/filter.o\n…\n      20:       1f 76 00 00 00 00 00 00         r6 -= r7\n…\n</code></pre>\n<p>However, that's not what the kernel actually runs. Apparently after the rewrite the subtraction becomes a complex, multi-step operation.</p>\n<p>To see what the kernel is actually running we can use little known <a href=\"https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/tools/bpf/bpftool?h=v5.0\">bpftool utility</a>. First, we need to load our BPF</p>\n<pre><code>$ ./run-bpf --stop-after-load 2 1\n[2]+  Stopped                 ./run-bpf 2 1\n</code></pre>\n<p>Then list all BPF programs loaded into the kernel with <code>bpftool prog list</code></p>\n<pre><code>$ sudo bpftool prog list\n…\n5951: socket_filter  name filter_alu64  tag 11186be60c0d0c0f  gpl\n        loaded_at 2019-04-05T13:01:24+0200  uid 1000\n        xlated 424B  jited 262B  memlock 4096B  map_ids 28786\n</code></pre>\n<p>The most recently loaded <code>socket_filter</code> must be our program (<code>filter_alu64</code>). Now we now know its id is 5951 and we can list its bytecode with</p>\n<pre><code>$ sudo bpftool prog dump xlated id 5951\n…\n  33: (79) r7 = *(u64 *)(r0 +0)\n  34: (b4) (u32) r11 = (u32) -1\n  35: (1f) r11 -= r6\n  36: (4f) r11 |= r6\n  37: (87) r11 = -r11\n  38: (c7) r11 s&gt;&gt;= 63\n  39: (5f) r6 &amp;= r11\n  40: (1f) r6 -= r7\n  41: (7b) *(u64 *)(r10 -16) = r6\n…\n</code></pre>\n<p>bpftool can also display the JITed code with: <code>bpftool prog dump jited id 5951</code>.</p>\n<p>As you see, subtraction is replaced with a series of opcodes. That is unless you are root. When running from root all is good</p>\n<pre><code>$ sudo ./run-bpf --stop-after-load 0 0\n[1]+  Stopped                 sudo ./run-bpf --stop-after-load 0 0\n$ sudo bpftool prog list | grep socket_filter\n659: socket_filter  name filter_alu64  tag 9e7ffb08218476f3  gpl\n$ sudo bpftool prog dump xlated id 659\n…\n  31: (79) r7 = *(u64 *)(r0 +0)\n  32: (1f) r6 -= r7\n  33: (7b) *(u64 *)(r10 -16) = r6\n…\n</code></pre>\n<p>If you've spent any time using eBPF, you must have experienced first hand the dreaded eBPF verifier. It's a merciless judge of all eBPF code that will reject any programs that it deems not worthy of running in kernel-space.</p>\n<p>What perhaps nobody has told you before, and what might come as a surprise, is that the very same verifier will actually also <a href=\"https://elixir.bootlin.com/linux/v4.20.13/source/kernel/bpf/verifier.c#L6421\">rewrite and patch up your eBPF code</a> as needed to make it safe.</p>\n<p>The problems with subtraction were introduced by an inconspicuous security fix to the verifier. The patch in question first landed in Linux 5.0 and was backported to 4.20.6 stable and 4.19.19 LTS kernel. <a href=\"https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=979d63d50c0c0f7bc537bf821e056cc9fe5abd38\">The over 2000 words long commit message</a> doesn't spare you any details on the attack vector it targets.</p>\n<p>The mitigation stems from <a href=\"https://nvd.nist.gov/vuln/detail/CVE-2019-7308\">CVE-2019-7308</a> vulnerability <a href=\"https://bugs.chromium.org/p/project-zero/issues/detail?id=1711\">discovered by Jann Horn at Project Zero</a>, which exploits pointer arithmetic, i.e. adding a scalar value to a pointer, to trigger speculative memory loads from out-of-bounds addresses. Such speculative loads change the CPU cache state and can be used to mount a <a href=\"https://googleprojectzero.blogspot.com/2018/01/reading-privileged-memory-with-side.html\">Spectre variant 1 attack</a>.</p>\n<p>To mitigate it the eBPF verifier rewrites any arithmetic operations on pointer values in such a way the result is always a memory location within bounds. The patch demonstrates how arithmetic operations on pointers get rewritten and we can spot a familiar pattern there</p>\n<!--kg-card-end: markdown--><p></p><figure class=\"kg-card kg-image-card\"><img src=\"http://blog.cloudflare.com/content/images/2019/04/bpf_commit.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p></p><!--kg-card-begin: markdown--><p>Wait a minute… What pointer arithmetic? We are just trying to subtract two scalar values. How come the mitigation kicks in?</p>\n<p>It shouldn't. It's a bug. The eBPF verifier keeps track of what kind of values the ALU is operating on, and in this corner case the state was ignored.</p>\n<p>Why running BPF as root is fine, you ask? If your program has <code>CAP_SYS_ADMIN</code> privileges, side-channel mitigations <a href=\"https://elixir.bootlin.com/linux/v5.0/source/kernel/bpf/verifier.c#L7218\">don't</a> <a href=\"https://elixir.bootlin.com/linux/v5.0/source/kernel/bpf/verifier.c#L3109\">apply</a>. As root you already have access to kernel address space, so nothing new can leak through BPF.</p>\n<p>After our report, <a href=\"https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=3612af783cf52c74a031a2f11b82247b2599d3cd\">the fix</a> has quickly landed in v5.0 kernel and got backported to stable kernels 4.20.15 and 4.19.28. Kudos to Daniel Borkmann for getting the fix out fast. However, kernel upgrades are hard and in the meantime we were left with code running in production that was not doing what it was supposed to.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id=\"32bitalutotherescue\">32-bit ALU to the rescue</h3>\n<p>As one of the eBPF maintainers <a href=\"https://lore.kernel.org/netdev/af0643e0-08a1-6326-2a80-71892de1bf56@iogearbox.net/\">has pointed out</a>, 32-bit arithmetic operations are not affected by the verifier bug. This opens a door for a work-around.</p>\n<p>eBPF registers, <code>r0</code>..<code>r10</code>, are 64-bits wide, but you can also access just the lower 32 bits, which are exposed as subregisters <code>w0</code>..<code>w10</code>. You can operate on the 32-bit subregisters using BPF ALU32 instruction subset. LLVM 7+ can generate eBPF code that uses this instruction subset. Of course, you need to you ask it nicely with trivial <code>-Xclang -target-feature -Xclang +alu32</code> toggle:</p>\n<pre><code>$ cat sub32.c\n#include &quot;common.h&quot;\n\nu32 sub32(u32 x, u32 y)\n{\n        return x - y;\n}\n$ clang -O2 -target bpf -Xclang -target-feature -Xclang +alu32 -c sub32.c\n$ llvm-objdump -S -no-show-raw-insn sub32.o\n…\nsub32:\n       0:       bc 10 00 00 00 00 00 00         w0 = w1\n       1:       1c 20 00 00 00 00 00 00         w0 -= w2\n       2:       95 00 00 00 00 00 00 00         exit\n</code></pre>\n<p>The <code>0x1c</code> <a href=\"https://elixir.bootlin.com/linux/v5.0/source/include/uapi/linux/bpf_common.h#L11\">opcode</a> of the instruction #1, which can be broken down as <code>BPF_ALU | BPF_X | BPF_SUB</code> (read more in the <a href=\"https://www.kernel.org/doc/Documentation/networking/filter.txt\">kernel docs</a>), is the 32-bit subtraction between registers we are looking for, as opposed to regular 64-bit subtract operation <code>0x1f = BPF_ALU64 | BPF_X | BPF_SUB</code>, which will get rewritten.</p>\n<p>Armed with this knowledge we can borrow a page from <a href=\"https://en.wikipedia.org/wiki/Arbitrary-precision_arithmetic\">bignum arithmetic</a> and subtract 64-bit numbers using just 32-bit ops:</p>\n<pre><code class=\"language-c\">u64 sub64(u64 x, u64 y)\n{\n        u32 xh, xl, yh, yl;\n        u32 hi, lo;\n\n        xl = x;\n        yl = y;\n        lo = xl - yl;\n\n        xh = x &gt;&gt; 32;\n        yh = y &gt;&gt; 32;\n        hi = xh - yh - (lo &gt; xl); /* underflow? */\n\n        return ((u64)hi &lt;&lt; 32) | (u64)lo;\n}\n</code></pre>\n<p>This code compiles as expected on normal architectures, like x86-64 or ARM64, but BPF Clang target plays by its own rules:</p>\n<pre><code>$ clang -O2 -target bpf -Xclang -target-feature -Xclang +alu32 -c sub64.c -o - \\\n  | llvm-objdump -S -\n…  \n      13:       1f 40 00 00 00 00 00 00         r0 -= r4\n      14:       1f 30 00 00 00 00 00 00         r0 -= r3\n      15:       1f 21 00 00 00 00 00 00         r1 -= r2\n      16:       67 00 00 00 20 00 00 00         r0 &lt;&lt;= 32\n      17:       67 01 00 00 20 00 00 00         r1 &lt;&lt;= 32\n      18:       77 01 00 00 20 00 00 00         r1 &gt;&gt;= 32\n      19:       4f 10 00 00 00 00 00 00         r0 |= r1\n      20:       95 00 00 00 00 00 00 00         exit\n</code></pre>\n<p>Apparently the compiler decided it was better to operate on 64-bit registers and discard the upper 32 bits. Thus we weren't able to get rid of the problematic <code>0x1f</code> opcode. Annoying, back to square one.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id=\"surelyabitofirwilldo\">Surely a bit of IR will do?</h3>\n<p>The problem was in Clang frontend - compiling C to IR. We know that BPF &quot;assembly&quot; backend for LLVM can generate bytecode that uses ALU32 instructions. Maybe if we tweak the Clang compiler's output just a little we can achieve what we want. This means we have to get our hands dirty with the LLVM Intermediate Representation (IR).</p>\n<p>If you haven't heard of LLVM IR before, now is a good time to do some <a href=\"http://www.aosabook.org/en/llvm.html\">reading</a><a href=\"#f2\"><sup>2</sup></a>. In short the LLVM IR is what Clang produces and LLVM BPF backend consumes.</p>\n<p>Time to write IR by hand! Here's a hand-tweaked <a href=\"https://github.com/cloudflare/cloudflare-blog/blob/master/2019-04-ebpf-alu32/bpf/sub64_ir.ll#L7\">IR variant</a> of our <code>sub64()</code> function:</p>\n<pre><code>define dso_local i64 @sub64_ir(i64, i64) local_unnamed_addr #0 {\n  %3 = trunc i64 %0 to i32      ; xl = (u32) x;\n  %4 = trunc i64 %1 to i32      ; yl = (u32) y;\n  %5 = sub i32 %3, %4           ; lo = xl - yl;\n  %6 = zext i32 %5 to i64\n  %7 = lshr i64 %0, 32          ; tmp1 = x &gt;&gt; 32;\n  %8 = lshr i64 %1, 32          ; tmp2 = y &gt;&gt; 32;\n  %9 = trunc i64 %7 to i32      ; xh = (u32) tmp1;\n  %10 = trunc i64 %8 to i32     ; yh = (u32) tmp2;\n  %11 = sub i32 %9, %10         ; hi = xh - yh\n  %12 = icmp ult i32 %3, %5     ; tmp3 = xl &lt; lo\n  %13 = zext i1 %12 to i32\n  %14 = sub i32 %11, %13        ; hi -= tmp3\n  %15 = zext i32 %14 to i64\n  %16 = shl i64 %15, 32         ; tmp2 = hi &lt;&lt; 32\n  %17 = or i64 %16, %6          ; res = tmp2 | (u64)lo\n  ret i64 %17\n}\n</code></pre>\n<p>It may not be pretty but it does produce <a href=\"https://github.com/cloudflare/cloudflare-blog/blob/master/2019-04-ebpf-alu32/bpf/sub64_ir.s#L5\">desired BPF code</a> when compiled<a href=\"#f3\"><sup>3</sup></a>. You will likely find the <a href=\"https://llvm.org/docs/LangRef.html\">LLVM IR reference</a> helpful when deciphering it.</p>\n<p>And voila! First working solution that produces correct results:</p>\n<pre><code>$ ./run-bpf -filter ir $[2**32] 1\narg0           4294967296 0x0000000100000000\narg1                    1 0x0000000000000001\ndiff           4294967295 0x00000000ffffffff\n</code></pre>\n<p>Actually using this hand-written IR function from C is tricky. See <a href=\"https://github.com/cloudflare/cloudflare-blog/blob/master/2019-04-ebpf-alu32/build.ninja#L27\">our code on GitHub</a>.</p>\n<!--kg-card-end: markdown--><p></p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"http://blog.cloudflare.com/content/images/2019/04/LED_DISP-1.JPG\" class=\"kg-image\" alt loading=\"lazy\"><figcaption>public domain <a href=\"https://en.wikipedia.org/wiki/File:LED_DISP.JPG\">image</a> by <a href=\"https://commons.wikimedia.org/wiki/User:Sergei_Frolov\">Sergei Frolov</a></figcaption></figure><p></p><!--kg-card-begin: markdown--><h3 id=\"thefinaltrick\">The final trick</h3>\n<p>Hand-written IR does the job. The downside is that linking IR modules to your C modules is hard. Fortunately there is a better way. You can persuade Clang to stick to 32-bit ALU ops in generated IR.</p>\n<p>We've already seen the problem. To recap, if we ask Clang to subtract 32-bit integers, it will operate on 64-bit values and throw away the top 32-bits. Putting C, IR, and eBPF side-by-side helps visualize this:</p>\n<!--kg-card-end: markdown--><p></p><figure class=\"kg-card kg-image-card\"><img src=\"http://blog.cloudflare.com/content/images/2019/04/sub32_v1.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p></p><!--kg-card-begin: markdown--><p>The trick to get around it is to declare the 32-bit variable that holds the result as <code>volatile</code>. You might already know the <a href=\"https://en.wikipedia.org/wiki/Volatile_(computer_programming)\"><code>volatile</code> keyword</a> if you've written Unix signal handlers. It basically tells the compiler that the value of the variable may change under its feet so it should refrain from reorganizing loads (reads) from it, as well as that stores (writes) to it might have side-effects so changing the order or eliminating them, by skipping writing it to the memory, is not allowed either.</p>\n<p>Using <code>volatile</code> makes Clang emit <a href=\"https://llvm.org/docs/LangRef.html#volatile-memory-accesses\">special loads and/or stores</a> at the IR level, which then on eBPF level translates to writing/reading the value from memory (stack) on every access. While this sounds not related to the problem at hand, there is a surprising side-effect to it:</p>\n<!--kg-card-end: markdown--><p></p><figure class=\"kg-card kg-image-card\"><img src=\"http://blog.cloudflare.com/content/images/2019/04/sub32_v2.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p></p><!--kg-card-begin: markdown--><p>With volatile access compiler doesn't promote the subtraction to 64 bits!  Don't ask me why, although I would love to hear an explanation. For now, consider this a hack. One that does not come for free - there is the overhead of going through the stack on each read/write.</p>\n<p>However, if we play our cards right we just might reduce it a little. We don't actually need the volatile load or store to happen, we just want the side effect. So instead of declaring the value as volatile, which implies that both reads and writes are volatile, let's try to make only the writes volatile with a help of a macro:</p>\n<pre><code class=\"language-c\">/* Emits a &quot;store volatile&quot; in LLVM IR */\n#define ST_V(rhs, lhs) (*(volatile typeof(rhs) *) &amp;(rhs) = (lhs))\n</code></pre>\n<p>If this macro looks strangely familiar, it's because it does the same thing as <a href=\"https://elixir.bootlin.com/linux/v5.1-rc5/source/include/linux/compiler.h#L214\"><code>WRITE_ONCE()</code> macro</a> in the Linux kernel. Applying it to our example:</p>\n<!--kg-card-end: markdown--><p></p><figure class=\"kg-card kg-image-card\"><img src=\"http://blog.cloudflare.com/content/images/2019/04/sub32_v3.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p></p><!--kg-card-begin: markdown--><p>That's another <a href=\"https://github.com/cloudflare/cloudflare-blog/blob/master/2019-04-ebpf-alu32/bpf/filter.c#L143\">hacky but working solution</a>. Pick your poison.</p>\n<!--kg-card-end: markdown--><p></p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"http://blog.cloudflare.com/content/images/2019/04/poison_bottles-2.jpg\" class=\"kg-image\" alt loading=\"lazy\"><figcaption><a href=\"https://creativecommons.org/licenses/by-sa/3.0/\">CC BY-SA 3.0</a> <a href=\"https://commons.wikimedia.org/wiki/File:D-BW-Kressbronn_aB_-_Kl%C3%A4ranlage_067.jpg\">image</a> by ANKAWÜ</figcaption></figure><p></p><!--kg-card-begin: markdown--><p>So there you have it - from C, to IR, and back to C to hack around a bug in eBPF verifier and be able to subtract 64-bit integers again. Usually you won't have to dive into LLVM IR or assembly to make use of eBPF. But it does help to know a little about it when things don't work as expected.</p>\n<p>Did I mention that 64-bit addition is also broken? Have fun fixing it!</p>\n<!--kg-card-end: markdown--><hr><!--kg-card-begin: markdown--><p><a name=\"f1\"><sup>1</sup></a> Okay, it was more like 3 months time until the bug was discovered and fixed.</p>\n<p><a name=\"f2\"><sup>2</sup></a> Some even think that it is <a href=\"https://idea.popcount.org/2013-07-24-ir-is-better-than-assembly/\">better than assembly</a>.</p>\n<p><a name=\"f3\"><sup>3</sup></a> How do we know? The litmus test is to look for statements matching <code>r[0-9] [-+]= r[0-9]</code> in BPF assembly.</p>\n<!--kg-card-end: markdown-->",
		"comment_id": "5cc6f341c4b60800c047815c",
		"feature_image": "http://blog.cloudflare.com/content/images/2019/04/Grant_mechanical_calculating_machine_1877.jpg",
		"featured": false,
		"visibility": "public",
		"created_at": "2019-04-29T13:51:13.000+01:00",
		"updated_at": "2019-05-03T15:32:45.000+01:00",
		"published_at": "2019-05-03T14:00:00.000+01:00",
		"custom_excerpt": "It is unlikely we can tell you anything new about the extended Berkeley Packet Filter, eBPF for short, if you've read all the great man pages, docs, guides, and some of our blogs out there. But we can tell you a war story, who doesn't like those? ",
		"codeinjection_head": null,
		"codeinjection_foot": null,
		"custom_template": null,
		"canonical_url": null,
		"authors": [
			{
				"id": "5d1644b141acde0011a9501b",
				"name": "Jakub Sitnicki",
				"slug": "jakub",
				"profile_image": "http://blog.cloudflare.com/content/images/2019/05/4_300698554542850065.jpg",
				"cover_image": "http://blog.cloudflare.com/content/images/2019/05/general@2x-2.png",
				"bio": null,
				"website": null,
				"location": null,
				"facebook": null,
				"twitter": null,
				"meta_title": null,
				"meta_description": null,
				"url": "http://blog.cloudflare.com/author/jakub/"
			}
		],
		"tags": [
			{
				"id": "5d16450341acde0011a9524d",
				"name": "eBPF",
				"slug": "ebpf",
				"description": null,
				"feature_image": null,
				"visibility": "public",
				"meta_title": null,
				"meta_description": null,
				"og_image": null,
				"og_title": null,
				"og_description": null,
				"twitter_image": null,
				"twitter_title": null,
				"twitter_description": null,
				"codeinjection_head": null,
				"codeinjection_foot": null,
				"canonical_url": null,
				"accent_color": null,
				"url": "http://blog.cloudflare.com/tag/ebpf/"
			},
			{
				"id": "5d16450341acde0011a951ff",
				"name": "Linux",
				"slug": "linux",
				"description": null,
				"feature_image": null,
				"visibility": "public",
				"meta_title": null,
				"meta_description": null,
				"og_image": null,
				"og_title": null,
				"og_description": null,
				"twitter_image": null,
				"twitter_title": null,
				"twitter_description": null,
				"codeinjection_head": null,
				"codeinjection_foot": null,
				"canonical_url": null,
				"accent_color": null,
				"url": "http://blog.cloudflare.com/tag/linux/"
			},
			{
				"id": "5d16450341acde0011a95214",
				"name": "Programming",
				"slug": "programming",
				"description": null,
				"feature_image": null,
				"visibility": "public",
				"meta_title": null,
				"meta_description": null,
				"og_image": null,
				"og_title": null,
				"og_description": null,
				"twitter_image": null,
				"twitter_title": null,
				"twitter_description": null,
				"codeinjection_head": null,
				"codeinjection_foot": null,
				"canonical_url": null,
				"accent_color": null,
				"url": "http://blog.cloudflare.com/tag/programming/"
			}
		],
		"primary_author": {
			"id": "5d1644b141acde0011a9501b",
			"name": "Jakub Sitnicki",
			"slug": "jakub",
			"profile_image": "http://blog.cloudflare.com/content/images/2019/05/4_300698554542850065.jpg",
			"cover_image": "http://blog.cloudflare.com/content/images/2019/05/general@2x-2.png",
			"bio": null,
			"website": null,
			"location": null,
			"facebook": null,
			"twitter": null,
			"meta_title": null,
			"meta_description": null,
			"url": "http://blog.cloudflare.com/author/jakub/"
		},
		"primary_tag": {
			"id": "5d16450341acde0011a9524d",
			"name": "eBPF",
			"slug": "ebpf",
			"description": null,
			"feature_image": null,
			"visibility": "public",
			"meta_title": null,
			"meta_description": null,
			"og_image": null,
			"og_title": null,
			"og_description": null,
			"twitter_image": null,
			"twitter_title": null,
			"twitter_description": null,
			"codeinjection_head": null,
			"codeinjection_foot": null,
			"canonical_url": null,
			"accent_color": null,
			"url": "http://blog.cloudflare.com/tag/ebpf/"
		},
		"url": "http://blog.cloudflare.com/ebpf-cant-count/",
		"excerpt": "It is unlikely we can tell you anything new about the extended Berkeley Packet Filter, eBPF for short, if you've read all the great man pages, docs, guides, and some of our blogs out there. But we can tell you a war story, who doesn't like those? ",
		"reading_time": 10,
		"access": true,
		"comments": false,
		"og_image": null,
		"og_title": null,
		"og_description": null,
		"twitter_image": null,
		"twitter_title": null,
		"twitter_description": null,
		"meta_title": null,
		"meta_description": null,
		"email_subject": null,
		"frontmatter": null,
		"feature_image_alt": null,
		"feature_image_caption": null
	}
}