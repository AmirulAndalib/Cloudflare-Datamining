<div class="post-content lh-copy gray1">
	<p><strong>Uma coleção de ferramentas do Cloudflare One para ajudar suas equipes a usar os serviços de IA com segurança</strong></p>
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2023/05/image1-18.png" class="kg-image" alt="A complete suite of Zero Trust security tools to get the most from AI" loading="lazy" width="1801" height="1013"></figure>
	<p>O Cloudflare One oferece a equipes de qualquer tamanho a capacidade de usar com segurança as melhores ferramentas da internet, sem dores de cabeça de gerenciamento ou desafios de desempenho. Temos o prazer de anunciar o Cloudflare One para IA, uma nova coleção de recursos que ajudam sua equipe a desenvolver os serviços de IA mais recentes, mantendo uma postura de segurança Zero Trust.</p>
	<h3 id="modelos-de-linguagem-ampla-maiores-desafios-de-seguran%C3%A7a">Modelos de linguagem ampla, maiores desafios de segurança</h3>
	<p>Um Modelo de linguagem ampla (LLM), como o GPT da OpenAI ou o Bard do Google, consiste em uma rede neural treinada com um conjunto de dados para prever e gerar texto com base em uma solicitação. Os usuários podem fazer perguntas, solicitar feedback e contar com o serviço para criar desde poesias até <a href="https://blog.samrhea.com/posts/2022/five-minute-ai-site?ref=blog.cloudflare.com" target="_blank">aplicativos no Cloudflare Workers</a>.</p>
	<p>As ferramentas também têm uma estranha semelhança com um ser humano real. Como em algumas conversas pessoais da vida real, o compartilhamento excessivo pode se tornar um <a href="https://mashable.com/article/samsung-chatgpt-leak-details?ref=blog.cloudflare.com" target="_blank">problema sério</a> com esses serviços de IA. Esse risco se multiplica devido aos tipos de casos de uso em que os modelos LLM prosperam. Essas ferramentas podem ajudar os desenvolvedores a resolver desafios difíceis de codificação ou os profissionais da informação a criar relatórios sucintos a partir de uma confusão de anotações. Embora útil, cada entrada inserida em uma solicitação torna-se um dado que sai do controle de sua organização.</p>
	<p>Algumas reações às ferramentas como o ChatGPT têm tentado banir o serviço completamente, seja em nível corporativo ou em <a href="https://www.reuters.com/technology/germany-principle-could-block-chat-gpt-if-needed-data-protection-chief-2023-04-03/?ref=blog.cloudflare.com" target="_blank">todo um país</a>. Nós não achamos que você precise fazer isso. O objetivo do Cloudflare One é permitir que você use com segurança as ferramentas de que precisa, onde quer que elas estejam, sem comprometer o desempenho. Esses recursos serão familiares para qualquer uso dos produtos Zero Trust no Cloudflare One, mas estamos entusiasmados em apresentar casos em que você pode usar as ferramentas disponíveis agora mesmo para permitir que sua equipe aproveite os recursos mais recentes dos LLMs.</p>
	<h3 id="medir-o-uso">Medir o uso</h3>
	<p>Os aplicativos SaaS tornam fácil para qualquer usuário se cadastrar e começar a testar. Essa conveniência também torna essas ferramentas um problema para os orçamentos de TI e as políticas de segurança. As equipes se referem a esse problema como "<a href="https://blog.cloudflare.com/introducing-shadow-it-discovery/">TI invisível</a>", a adoção de aplicativos e serviços fora dos canais aprovados em uma organização.</p>
	<p>Em termos de orçamento, ouvimos de clientes pioneiros que sabem que os membros de suas equipes estão começando a experimentar LLMs, mas não têm certeza de como abordar a tomada de decisão de licenciamento comercial. Quais serviços e recursos seus usuários precisam e quantas licenças eles devem adquirir?</p>
	<p>Do lado da segurança, as IAs podem ser revolucionárias para realizar o trabalho, mas aterrorizantes para as políticas de controle de dados. Os membros da equipe tratam essas IAs como "conselheiros" para problemas difíceis. Os serviços convidam os usuários a trazerem suas dúvidas ou desafios. Às vezes, o contexto dentro dessas solicitações pode conter informações confidenciais que nunca devem sair de uma organização. Mesmo que as equipes selecionem e aprovem um único fornecedor, os membros de sua organização podem preferir outra IA e continuar a usá-la em seu fluxo de trabalho.</p>
	<p>Os clientes do Cloudflare One em qualquer plano <a href="https://developers.cloudflare.com/cloudflare-one/analytics/access/?ref=blog.cloudflare.com" target="_blank">agora podem analisar</a> o uso de IAs. Seu departamento de TI pode implantar o Cloudflare Gateway e observar passivamente quantos usuários estão selecionando quais serviços como forma de começar a definir o escopo dos planos de licenciamento corporativo.</p>
	<figure class="kg-card kg-image-card kg-width-wide"><img src="https://blog.cloudflare.com/content/images/2023/05/image6-5.png" class="kg-image" alt="" loading="lazy" width="1879" height="682"></figure>
	<p>Os administradores também podem bloquear o uso desses serviços com um único clique, mas esse não é o nosso objetivo hoje. Você pode querer usar esse recurso se selecionar o ChatGPT como seu modelo aprovado e quiser garantir que os membros da equipe não continuem a usar alternativas, mas esperamos que você não bloqueie todos esses serviços completamente. A prioridade da Cloudflare é permitir que você use essas ferramentas com segurança.</p>
	<h3 id="controlar-o-acesso-a-apis">Controlar o acesso a APIs</h3>
	<p>Quando nossas equipes começaram a experimentar o serviço ChatGPT da OpenAI, ficamos surpresos com o que já sabia sobre o Cloudflare. Pedimos ao ChatGPT para criar aplicativos com <a href="https://workers.cloudflare.com/?ref=blog.cloudflare.com" target="_blank">Cloudflare Workers</a> ou nos orientar sobre como configurar uma política do <a href="https://www.cloudflare.com/products/zero-trust/access/?ref=blog.cloudflare.com" target="_blank">Cloudflare Access</a> e, na maioria dos casos, os resultados foram precisos e úteis.</p>
	<p>Em alguns casos, os resultados erraram o alvo. As IAs estavam usando informações desatualizadas ou fizemos perguntas sobre recursos lançados recentemente. Felizmente, essas IAs podem aprender e podemos ajudar. Podemos treinar esses modelos com entradas com escopo e <a href="https://openai.com/blog/chatgpt-plugins?ref=blog.cloudflare.com" target="_blank">conectar plug-ins</a> para fornecer aos nossos clientes melhores experiências guiadas por IA ao usar os serviços da Cloudflare.</p>
	<p>Ouvimos clientes que querem fazer o mesmo e, como nós, precisam compartilhar dados de treinamento com segurança e conceder acesso de plug-in para um serviço de IA. O pacote de segurança do Cloudflare One vai além dos usuários humanos e pode oferecer às equipes a capacidade de compartilhar com segurança o acesso Zero Trust a dados confidenciais por meio de APIs.</p>
	<p>Primeiro, as equipes podem criar <a href="https://developers.cloudflare.com/cloudflare-one/identity/service-tokens/?ref=blog.cloudflare.com" target="_blank">tokens de serviço</a> que os serviços externos devem apresentar para acessar os dados disponibilizados por meio do Cloudflare One. Os administradores podem fornecer esses tokens aos sistemas que fazem solicitações de API e registrar cada solicitação. Conforme necessário, as equipes podem revogar esses tokens com um único clique.</p>
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2023/05/download-7.png" class="kg-image" alt="" loading="lazy" width="1600" height="1317"></figure>
	<p>Depois de criar e emitir tokens de serviço, os administradores podem criar políticas para permitir que serviços específicos acessem seus dados de treinamento. Essas políticas verificam o token de serviço e podem ser estendidas para verificar o país, o endereço de IP ou um certificado mTLS. As políticas também podem ser criadas para exigir que usuários humanos se autentiquem com um provedor de identidade e concluam um prompt de MFA antes de acessar dados ou serviços de treinamento confidenciais.</p>
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2023/05/download--1--4.png" class="kg-image" alt="" loading="lazy" width="1600" height="1100"></figure>
	<p>Quando as equipes estão prontas para permitir que um serviço de IA se conecte à sua infraestrutura, elas podem fazer isso sem abrir brechas em seus firewalls usando o <a href="https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/?ref=blog.cloudflare.com" target="_blank">Cloudflare Tunnel</a>. O Cloudflare Tunnel criará uma conexão criptografada somente de saída para a rede da Cloudflare, onde cada solicitação será verificada em relação às regras de acesso configuradas para um ou mais serviços protegidos pelo Cloudflare One.</p>
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2023/05/download--2--3.png" class="kg-image" alt="" loading="lazy" width="1600" height="1100"></figure>
	<p>O controle de acesso Zero Trust da Cloudflare oferece a capacidade de impor a autenticação em todas as solicitações feitas aos dados que sua organização decidir fornecer a essas ferramentas. Isso ainda deixa uma lacuna nos dados que os membros de sua equipe podem compartilhar por conta própria.</p>
	<h3 id="restringir-uploads-de-dados">Restringir uploads de dados</h3>
	<p>Os administradores podem selecionar um serviço de IA, bloquear alternativas de TI invisível e controlar cuidadosamente o acesso ao seu material de treinamento, mas os humanos ainda estão envolvidos nesses experimentos de IA. Qualquer um de nós pode acidentalmente causar um incidente de segurança ao compartilhar informações demais no processo de uso de um serviço de IA, mesmo um serviço aprovado.</p>
	<p>Esperamos que os ambientes de testes de IA continuem evoluindo para oferecer mais recursos de gerenciamento de dados, mas não achamos que você deva esperar por isso para começar a adotar esses serviços como parte do seu fluxo de trabalho. O serviço de <a href="https://developers.cloudflare.com/cloudflare-one/policies/data-loss-prevention/dlp-policies/?ref=blog.cloudflare.com" target="_blank">Prevenção de Perda de Dados (DLP) da Cloudflare</a> pode fornecer uma proteção para evitar o compartilhamento excessivo antes que se torne um incidente para a sua equipe de segurança.</p>
	<p>Primeiro, diga-nos quais dados são importantes para você. Oferecemos opções simples e pré-configuradas que lhe permitem verificar coisas que se assemelham a números de seguro social ou números de cartão de crédito. O DLP da Cloudflare também pode buscar padrões com base em expressões regulares configuradas pela sua equipe.</p>
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2023/05/download--3--3.png" class="kg-image" alt="" loading="lazy" width="1600" height="1100"></figure>
	<p>Depois de definir os dados que nunca devem sair de sua organização, você pode criar regras granulares sobre como eles podem ou não ser compartilhados com serviços de IA. Talvez alguns usuários sejam aprovados para experimentar projetos que contenham dados confidenciais; nesse caso, você pode criar uma regra que permita apenas que um Active Directory ou grupo Okta faça upload desse tipo de informação enquanto todos os outros ficam bloqueados.</p>
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2023/05/download--4--3.png" class="kg-image" alt="" loading="lazy" width="1600" height="1100"></figure>
	<h3 id="controle-o-uso-sem-um-proxy">Controle o uso sem um proxy</h3>
	<p>As ferramentas no post do blog de hoje se concentram em recursos que se aplicam a dados em movimento. Também queremos garantir que configurações incorretas nos aplicativos não levem a violações de segurança. Por exemplo, o novo recurso de plug-in no ChatGPT traz o conhecimento e os fluxos de trabalho de serviços externos para o fluxo de interação com a IA. No entanto, isso também pode fazer com que os serviços por trás dos plug-ins tenham mais acesso do que você deseja. </p>
	<p>O <a href="https://www.cloudflare.com/products/zero-trust/casb/?ref=blog.cloudflare.com" target="_blank">agente de segurança de acesso à nuvem</a> (CASB) da Cloudflare verifica seus aplicativos SaaS em busca de possíveis problemas que podem ocorrer quando os usuários fazem alterações. Seja alertando sobre arquivos que alguém acidentalmente tornou públicos na internet ou verificando se seus <a href="https://developers.cloudflare.com/cloudflare-one/applications/scan-apps/casb-integrations/github/?ref=blog.cloudflare.com#security-findings" target="_blank">repositórios GitHub têm os controles de associação corretos</a>, o CASB da Cloudflare remove o esforço manual necessário para verificar cada configuração em busca de possíveis problemas em seus aplicativos SaaS.</p>
	<p>Disponível em breve, estamos trabalhando em novas integrações com serviços populares de IA para verificar configurações incorretas. Como a maioria dos usuários desses serviços, ainda estamos aprendendo mais sobre onde possíveis acidentes podem ocorrer e estamos entusiasmados em fornecer aos administradores que usam nosso CASB nossa primeira onda de controles para serviços de IA.</p>
	<h3 id="o-que-vem-a-seguir">O que vem a seguir?</h3>
	<p>A utilidade dessas ferramentas só vai acelerar. A capacidade dos serviços de IA de treinar e gerar resultados continuará facilitando para os desenvolvedores de qualquer área criar a próxima grande novidade.</p>
	<p>Compartilhamos um objetivo semelhante. Os produtos da Cloudflare focados em ajudar os usuários a desenvolver aplicativos e serviços, nossa <a href="https://workers.cloudflare.com/?ref=blog.cloudflare.com" target="_blank">plataforma Workers</a>, eliminam preocupações como onde implantar seu aplicativo ou como escalar seus serviços. A Cloudflare resolve esses problemas para que os usuários possam se concentrar na criação. Combinado com os serviços de IA, esperamos ver milhares de novos desenvolvedores lançando a próxima onda de produtos criados na Cloudflare e inspirados pelo treinamento e geração de IA.</p>
	<p>Já vimos dezenas de projetos, que foram construídos no Cloudflare Workers, prosperarem usando orientações de ferramentas como o ChatGPT. Planejamos lançar novas integrações com esses modelos para tornar isso ainda mais perfeito, trazendo uma orientação específica da Cloudflare melhor para a experiência de chat.</p>
	<p>Também sabemos que o risco de segurança dessas ferramentas vai aumentar. Continuaremos a trazer funcionalidades para o Cloudflare One que visam ficar um passo à frente dos riscos à medida que evoluem com esses serviços. Pronto para começar? Inscreva-se aqui para começar a usar o Cloudflare One gratuitamente para equipes de até 50 usuários.</p>
</div>