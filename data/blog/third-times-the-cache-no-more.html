<div class="mb2 gray5">5 min read</div>
<div class="post-content lh-copy gray1">
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2021/03/image1-23.png" class="kg-image" alt="Third Timeâ€™s the Cache, No More" loading="lazy"></figure>
	<p>Caching is a big part of how Cloudflare CDN makes the Internet faster and more reliable. When a visitor to a customerâ€™s website requests an asset, we retrieve it from the customerâ€™s origin server. After that first request, in many cases we <em>cache </em>that asset. Whenever anyone requests it again, we can serve it from one of our data centers close to them, dramatically speeding up load times.</p>
	<p>Did you notice the small caveat? We cache after the <em>first</em> request in <em>many</em> cases, not all. One notable exception since 2010 up until now: requests with <em>query strings</em>. When a request came with a query string (think <a href="https://example.com/image.jpg?width=500">https://example.com/image.jpg?width=500</a>; the <code>?width=500</code> is the query string), we needed to see it a whole <em>three </em>times before we would cache it on our <a href="https://support.cloudflare.com/hc/en-us/articles/200168256-Understand-Cloudflare-Caching-Level">default cache level</a>. Weird!</p>
	<p>This is a short tale of that strange exception, why we thought we needed it, and how, more than ten years later, we showed ourselves that we didnâ€™t.</p>
	<h3 id="two-misses-too-many">Two MISSes too many</h3>
	<p>To see the exception in action, hereâ€™s a command we ran a couple weeks ago. It requests an image hosted on <code>example.com</code> five times and prints each responseâ€™s <a href="https://support.cloudflare.com/hc/en-us/articles/200172516-Understanding-Cloudflare-s-CDN#h_bd959d6a-39c0-4786-9bcd-6e6504dcdb97">CF-Cache-Status header</a>. That header tells us what the cache did while serving the request.</p><!--kg-card-begin: markdown-->
	<pre><code>â¯ for i in {1..5}; do curl -svo /dev/null example.com/image.jpg 2&gt;&amp;1 | grep -e 'CF-Cache-Status'; sleep 3; done
&lt; CF-Cache-Status: MISS
&lt; CF-Cache-Status: HIT
&lt; CF-Cache-Status: HIT
&lt; CF-Cache-Status: HIT
&lt; CF-Cache-Status: HIT
</code></pre>
	<!--kg-card-end: markdown-->
	<p>The MISS means that we couldnâ€™t find the asset in the cache and had to retrieve it from the origin server. On the HITs, we served the asset from cache.</p>
	<p>Now, just by adding a query string to the same request (<code>?query=val</code>):</p><!--kg-card-begin: markdown-->
	<pre><code>â¯ for i in {1..5}; do curl -svo /dev/null example.com/image.jpg\?query\=val 2&gt;&amp;1 | grep -e 'CF-Cache-Status'; sleep 3; done
&lt; CF-Cache-Status: MISS
&lt; CF-Cache-Status: MISS
&lt; CF-Cache-Status: MISS
&lt; CF-Cache-Status: HIT
&lt; CF-Cache-Status: HIT
</code></pre>
	<!--kg-card-end: markdown-->
	<p>There they are - three MISSes, meaning two extra trips to the customer origin!</p>
	<p>We traced this surprising behavior back to a git commit from Cloudflareâ€™s earliest days in 2010. Since then, it has spawned chat threads, customer escalations, and even an internal Solutions Engineering blog post that christened it the â€œthird timeâ€™s the charmâ€ quirk.</p>
	<p>It would be much less confusing if we could make the query string behavior align with the others, but why was the quirk here to begin with?</p>
	<h3 id="unpopular-queries">Unpopular queries</h3>
	<p>From an engineering perspective, forcing three MISSes for query strings can make sense as a way to protect ourselves from unnecessary disk writes.</p>
	<p>Thatâ€™s because for many requests with query strings in the URL, we may never see that URL requested again.</p>
	<ol>
		<li>Some query strings simply pass along data to the origin server that may not actually result in a different response from the base URL, for example, a visitorâ€™s browser metadata. We end up caching the same response behind many different, potentially unique, cache keys.</li>
		<li>Some query strings are <em>intended </em>to bypass caches. These â€œcache bustingâ€ requests append randomized query strings in order to force pulling from the origin, a strategy that some <a href="https://support.google.com/campaignmanager/answer/2837435?hl=en#zippy=%2Chow-does-cache-busting-work">ad managers use to count impressions</a>.</li>
	</ol>
	<p>Unpopular requests are not a new problem for us. Previously, <a href="https://blog.cloudflare.com/why-we-started-putting-unpopular-assets-in-memory">we wrote about how we use an in-memory transient cache</a> to store requests we only ever see once (dubbed â€œone-hit-wondersâ€) so that they are never written to disk. This transient cache, enabled for just a subset of traffic, reduces our disk writes by 20-25%.</p>
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2021/03/image2-15.png" class="kg-image" alt="This transient cache, enabled for just a subset of traffic, reduces our disk writes by 20-25%." loading="lazy"></figure>
	<p>Was this behavior from 2010 giving us similar benefits? Since then, our network has grown from 10,000 Internet properties to 25 million. It was time to re-evaluate. Just how much would our disk writes increase if we cached on the first request? How much better would cache hit ratios be?</p>
	<h3 id="hypotheses-querying-the-cache">Hypotheses: querying the cache</h3>
	<p>Good news: our metrics showed only around 3.5% of requests use the default cache level with query strings. Thus, we shouldnâ€™t expect more than a few percentage points difference in disk writes. Less good: <a href="https://www.cloudflare.com/learning/cdn/what-is-a-cache-hit-ratio">cache hit rate</a> shouldnâ€™t increase much either.</p>
	<p>On the other hand, we also found that a significant portion of these requests are images, which could potentially take up lots of disk space and hike up cache eviction rates. Enough napkin math - we needed to start assessing real world data.</p>
	<h3 id="a-b-testing-caching-the-queries">A/B testing: caching the queries</h3>
	<p>We were able to validate our hypotheses using an <a href="https://en.wikipedia.org/wiki/A/B_testing">A/B test</a>, where half the machines in a data center use the old behavior and half do not. This enabled us to control for Internet traffic fluctuations over time and get more precise impact numbers.</p>
	<p>Other considerations: we limited the test to one data center handling a small slice of our traffic to minimize the impact of any negative side effects. We also disabled transient cache, which would nullify some of the I/O costs we expected to observe. By turning transient cache off for the experiment, we should see the upper bound of the disk write increase.</p>
	<p>We ran this test for a couple days and, as hypothesized, found a minor but acceptable increase in disk writes per request to the tune of 2.5%.</p>
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2021/03/image3-17.png" class="kg-image" alt="We ran this test for a couple days and, as hypothesized, found a minor but acceptable increase in disk writes per request to the tune of 2.5%." loading="lazy"></figure>
	<p>Whatâ€™s more, we saw a modest hit rate increase of around +3% on average for our Enterprise customers. More hits meant fewer trips to origin servers and thus bandwidth savings for customers: in this case, a -5% decrease in total bytes served from origin.</p>
	<p>Note that we saw hit rate increases for certain customers across <em>all </em>plan types. Those with the biggest boost had a variety of query strings across different visitor populations (e.g. appending query strings such as <code>?resize=100px:*&amp;output-quality=60</code> <a href="https://developers.cloudflare.com/images/resizing-with-workers">to optimize serving images for different screen sizes</a>). A few additional HITs for many different, but still popular, cache keys really added up.</p>
	<h3 id="revisiting-old-assumptions">Revisiting old assumptions</h3>
	<p>What the aggregate hit rate increase implied was that for a significant portion of customers, our old query string behavior was too defensive. We were overestimating the proportion of query string requests that were one-hit-wonders.</p>
	<p>Given that these requests are a relatively small percentage of total traffic, we didnâ€™t expect to see massive hit rate improvements. In fact, if the assumptions about many query string requests being one-hit-wonders were correct, we should hardly be seeing any difference at all. (One-hit-wonders are actually â€œone MISS wondersâ€ in the context of hit rate.) Instead, we saw hit rate increases proportional to the affected traffic percentage. This, along with the minor I/O cost increases, signaled that the benefits of removing the behavior would outweigh the benefits of keeping it.</p>
	<p>Using a data-driven approach, we determined our caution around caching query string requests wasnâ€™t nearly as effective at preventing disk writes of unpopular requests compared to our newer efforts, such as transient cache. It was a good reminder for us to re-examine past assumptions from time-to-time and see if they still held.</p>
	<figure class="kg-card kg-image-card"><img src="https://blog.cloudflare.com/content/images/2021/03/image4-15.png" class="kg-image" alt="Revisiting old assumptions" loading="lazy"></figure>
	<p>Post-experiment, we gradually rolled out the change to verify that our cost expectations were met. At this time, weâ€™re happy to report that weâ€™ve left the â€œthird timeâ€™s the charmâ€ quirk behind for the history books. Long live â€œcache at first sight.â€</p>
</div>