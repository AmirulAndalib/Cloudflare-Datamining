{
	"@context": "https://schema.org",
	"@type": "Article",
	"publisher": {
		"@type": "Organization",
		"name": "The Cloudflare Blog",
		"logo": {
			"@type": "ImageObject",
			"url": "https://blog-cloudflare-com-assets.storage.googleapis.com/2019/06/logo-cloudflare-dark-1.svg",
			"width": 109,
			"height": 40.5
		}
	},
	"author": {
		"@type": "Person",
		"name": "Marek Majkowski",
		"image": "http://blog.cloudflare.com/content/images/2017/03/b5967d6c687939594adb6992723d0529.jpeg",
		"url": "https://blog.cloudflare.com/author/marek-majkowski/",
		"sameAs": [
			"https://twitter.com/majek04"
		]
	},
	"headline": "Why does one NGINX worker take all the load?",
	"url": "https://blog.cloudflare.com/the-sad-state-of-linux-socket-balancing/",
	"datePublished": "2017-10-23T12:57:36.000Z",
	"dateModified": "2022-06-10T12:23:25.000Z",
	"image": "http://blog.cloudflare.com/content/images/2017/10/37470469351_49281d8b66_b-1.jpg",
	"keywords": "NGINX, Developers, Cloudflare Workers, Serverless, JavaScript, TCP",
	"description": "Scaling up TCP servers is usually straightforward. Most deployments start by using a single process setup. When the need arises more worker processes are added. ",
	"mainEntityOfPage": {
		"@type": "WebPage",
		"@id": "http://blog.cloudflare.com/"
	}
}